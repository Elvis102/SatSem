#====================================
# PIPELINE PARAMETRIZADO POR A√ëO
# Predicci√≥n, Mosaico y Matriz de Confusi√≥n
# ‚úÖ CON POST-PROCESAMIENTO MORFOL√ìGICO
# ‚úÖ OPTIMIZADO: Sin normalizaci√≥n redundante
#====================================
#
# OPTIMIZACI√ìN CR√çTICA (Dic 2024):
# ---------------------------------
# Se identific√≥ que las im√°genes Sentinel-2 procesadas en Google Earth Engine
# ya est√°n normalizadas [0, 1]. La normalizaci√≥n percentil adicional durante
# la inferencia estaba comprimiendo innecesariamente el rango din√°mico espectral.
#              
# CAMBIOS:
# - Eliminada normalizaci√≥n percentil en predict_tile()
# - Threshold optimizado a 0.50 (para valores espectrales reales)
# - Ganancia estimada: +8-10 pp en recall, -2 pp en precision
#
# REFERENCIA:
# Ver an√°lisis de normalizaci√≥n en inspeccionar_teselas.py
# como correr el pipeline: cd /Users/elvissanchez/Documents/GitHub/thesis_project/notebooks/satseg-main
# ¬øPorque tengo que ubicarme en satseg-main para que coloque la carpeta predicciones_por_a√±o en la ruta correcta?
# uv run predict_and_mosaic_with_metrics.py
#====================================

from src.module import Module
from src.metrics import iou
from src.models.multi_branch_unet import MultiBranchUNetWrapper
import torch
import segmentation_models_pytorch as smp
import os
import numpy as np
import rasterio
from rasterio.merge import merge
from rasterio.warp import calculate_default_transform, reproject, Resampling
from rasterio.crs import CRS
from rasterio.plot import show
from pathlib import Path
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
import glob
from tqdm import tqdm
import warnings
import json
import seaborn as sns
from scipy.ndimage import binary_closing, binary_opening  # ‚Üê NUEVO IMPORT
import geopandas as gpd  # Para shapefiles
from rasterio.mask import mask as rasterio_mask  # Para enmascarar

warnings.filterwarnings('ignore', category=RuntimeWarning)


#====================================
# üîß FUNCIONES HELPER PARA CRS
#====================================

def is_crs_geographic(crs):
    """
    Detecta si un CRS es geogr√°fico (grados) o proyectado (metros)
    
    ‚úÖ MEJORADO: Verifica unidades y m√∫ltiples m√©todos de detecci√≥n
    
    Args:
        crs: rasterio.crs.CRS object
    
    Returns:
        tuple: (is_geographic: bool, detection_method: str, additional_info: dict)
    
    Ejemplos:
        - EPSG:4326 (WGS84) ‚Üí (True, ..., {'units': 'degrees'})
        - EPSG:32717 (UTM 17S) ‚Üí (False, ..., {'units': 'meters', 'zone': '17S'})
        - EPSG:32618 (UTM 18N) ‚Üí (False, ..., {'units': 'meters', 'zone': '18N'})
    """
    
    additional_info = {}
    
    # M√©todo 1: Usar propiedad is_geographic de rasterio (m√°s confiable)
    try:
        is_geographic = crs.is_geographic
        
        # Verificar unidades como confirmaci√≥n adicional
        try:
            linear_units = crs.linear_units
            additional_info['units'] = linear_units
            
            # Las unidades geogr√°ficas son t√≠picamente 'degree' o 'degrees'
            if linear_units and 'degree' in str(linear_units).lower():
                additional_info['units_type'] = 'degrees'
            elif linear_units and any(unit in str(linear_units).lower() for unit in ['metre', 'meter', 'm']):
                additional_info['units_type'] = 'meters'
        except:
            pass
            
        return is_geographic, "rasterio.is_geographic", additional_info
    except:
        pass
    
    # M√©todo 2: Verificar c√≥digo EPSG
    try:
        epsg_code = crs.to_epsg()
        
        if epsg_code:
            additional_info['epsg'] = epsg_code
            
            # EPSG 326xx (UTM Norte) y 327xx (UTM Sur) son proyectados
            if 32600 <= epsg_code <= 32660:  # UTM zones North
                zone_num = epsg_code - 32600
                additional_info['zone'] = f"{zone_num}N"
                additional_info['units'] = 'meters'
                return False, f"EPSG:{epsg_code} (UTM {zone_num}N)", additional_info
            elif 32700 <= epsg_code <= 32760:  # UTM zones South
                zone_num = epsg_code - 32700
                additional_info['zone'] = f"{zone_num}S"
                additional_info['units'] = 'meters'
                return False, f"EPSG:{epsg_code} (UTM {zone_num}S)", additional_info
            elif epsg_code == 4326:  # WGS84
                additional_info['datum'] = 'WGS84'
                additional_info['units'] = 'degrees'
                return True, "EPSG:4326 (WGS84)", additional_info
            elif epsg_code == 4269:  # NAD83
                additional_info['datum'] = 'NAD83'
                additional_info['units'] = 'degrees'
                return True, "EPSG:4269 (NAD83)", additional_info
            elif 4000 <= epsg_code < 5000:  # Generalmente geogr√°ficos
                additional_info['units'] = 'degrees'
                return True, f"EPSG:{epsg_code} (geogr√°fico)", additional_info
            elif epsg_code in range(2000, 32600):  # Muchos sistemas proyectados
                additional_info['units'] = 'meters'
                return False, f"EPSG:{epsg_code} (proyectado)", additional_info
            else:
                # Otros c√≥digos - probablemente proyectados
                additional_info['units'] = 'unknown'
                return False, f"EPSG:{epsg_code} (proyectado)", additional_info
    except:
        pass
    
    # M√©todo 3: An√°lisis de string del CRS (fallback)
    try:
        crs_string = str(crs).upper()
        additional_info['crs_string'] = crs_string[:100]  # Primeros 100 caracteres
        
        geographic_indicators = ['4326', 'WGS 84', 'GEOGCS', 'GEOGRAPHIC', 
                                'LATITUDE', 'LONGITUDE', 'DEGREE']
        projected_indicators = ['UTM', 'PROJCS', 'PROJECTED', 'METRE', 'METER']
        
        has_geographic = any(ind in crs_string for ind in geographic_indicators)
        has_projected = any(ind in crs_string for ind in projected_indicators)
        
        if has_projected:
            additional_info['units'] = 'meters'
            return False, "string analysis (projected)", additional_info
        elif has_geographic:
            additional_info['units'] = 'degrees'
            return True, "string analysis (geographic)", additional_info
    except:
        pass
    
    # Por defecto, asumir proyectado (m√°s seguro para no forzar reproyecci√≥n)
    additional_info['fallback'] = True
    return False, "fallback (assumed projected)", additional_info


#====================================
# ‚≠ê CONFIGURACI√ìN CENTRALIZADA POR A√ëO
#====================================

class YearConfig:
    """
    Configuraci√≥n parametrizada por a√±o para an√°lisis multitemporal
    
    Uso:
        config = YearConfig(year=2021, base_dir='/path/to/data')
        images_dir = config.images_dir
        masks_dir = config.masks_dir
    """
    
    def __init__(self, year, base_dir, checkpoint_path, output_base_dir='predicciones'):
        """
        Args:
            year: A√±o de an√°lisis (ej: 2021, 2022, 2023)
            base_dir: Directorio base donde est√°n las carpetas Manglar_[A√ëO]_*
            checkpoint_path: Ruta al checkpoint del modelo
            output_base_dir: Directorio base para outputs (se crear√° subdir por a√±o)
        """
        self.year = year
        self.base_dir = Path(base_dir)
        self.checkpoint_path = checkpoint_path
        
        # Construir nombres de carpetas seg√∫n patr√≥n
        self.images_folder_name = f"Manglar_{year}_images"
        self.masks_folder_name = f"Manglar_{year}_masks"
        
        # Rutas completas
        self.images_dir = self.base_dir / self.images_folder_name
        self.masks_dir = self.base_dir / self.masks_folder_name
        
        # Directorio de salida espec√≠fico por a√±o
        self.output_base_dir = Path(output_base_dir) / f"year_{year}"
        self.predictions_dir = self.output_base_dir / 'teselas_predichas'
        self.mosaic_dir = self.output_base_dir / 'mosaico'
        self.metrics_dir = self.output_base_dir / 'metricas'
        self.visualizations_dir = self.output_base_dir / 'visualizaciones'

        # Crear directorios de salida
        self.predictions_dir.mkdir(parents=True, exist_ok=True)
        self.mosaic_dir.mkdir(parents=True, exist_ok=True)
        self.metrics_dir.mkdir(parents=True, exist_ok=True)
        self.visualizations_dir.mkdir(parents=True, exist_ok=True)
        
        # Validar que existan las carpetas de entrada
        self._validate_directories()
    
    def _validate_directories(self):
        """Valida que existan las carpetas de im√°genes (m√°scaras son opcionales)"""
        if not self.images_dir.exists():
            raise ValueError(
                f"‚ùå No se encontr√≥ la carpeta de im√°genes: {self.images_dir}\n"
                f"   Verifica que exista: {self.base_dir}/{self.images_folder_name}"
            )
        
        # Verificar que haya archivos .tif en im√°genes
        tif_files = list(self.images_dir.glob("*.tif"))
        if len(tif_files) == 0:
            raise ValueError(
                f"‚ùå No se encontraron archivos .tif en: {self.images_dir}"
            )
        
        print(f"‚úÖ Carpeta de im√°genes encontrada: {self.images_dir}")
        print(f"   Archivos .tif encontrados: {len(tif_files)}")
        
        # Las m√°scaras son opcionales
        if self.masks_dir.exists():
            mask_files = list(self.masks_dir.glob("*.tif"))
            print(f"‚úÖ Carpeta de m√°scaras encontrada: {self.masks_dir}")
            print(f"   Archivos .tif encontrados: {len(mask_files)}")
        else:
            print(f"‚ö†Ô∏è  No se encontr√≥ carpeta de m√°scaras: {self.masks_dir}")
            print(f"   La matriz de confusi√≥n no estar√° disponible")
    
    def get_summary(self):
        """Retorna resumen de la configuraci√≥n"""
        return {
            'year': self.year,
            'base_dir': str(self.base_dir),
            'images_dir': str(self.images_dir),
            'masks_dir': str(self.masks_dir),
            'output_dir': str(self.output_base_dir),
            'images_exist': self.images_dir.exists(),
            'masks_exist': self.masks_dir.exists()
        }


#====================================
# FUNCIONES DE MATRIZ DE CONFUSI√ìN
#====================================

def calculate_confusion_matrix_from_files(pred_files, masks_dir):
    """
    Calcula la matriz de confusi√≥n comparando predicciones con m√°scaras ground truth
    
    ‚úÖ CORREGIDO: Excluye m√°scaras vac√≠as (solo 0s) y maneja NaN
    
    Args:
        pred_files: Lista de rutas a predicciones
        masks_dir: Path object del directorio con m√°scaras
    
    Returns:
        cm: Matriz de confusi√≥n 2x2
        metrics: Diccionario con m√©tricas
        valid_count: N√∫mero de teselas con m√°scaras v√°lidas
    """
    
    if not masks_dir.exists():
        print(f"\n‚ö†Ô∏è  Directorio de m√°scaras no existe: {masks_dir}")
        return None, None, 0
    
    TP = FP = TN = FN = 0
    valid_count = 0
    skipped_empty = 0      # M√°scaras vac√≠as (solo 0s)
    skipped_invalid = 0    # M√°scaras con problemas
    skipped_nan = 0        # M√°scaras con NaN
    
    # ‚≠ê NUEVO: Listas para rastrear nombres de teselas excluidas
    empty_masks = []       # Nombres de m√°scaras vac√≠as
    nan_masks = []         # Nombres de m√°scaras con NaN
    invalid_masks = []     # Nombres de m√°scaras inv√°lidas
    
    print(f"\nüîç Buscando m√°scaras ground truth en: {masks_dir}")
    
    for pred_path in tqdm(pred_files, desc="Calculando matriz de confusi√≥n"):
        # Extraer nombre base de la predicci√≥n
        pred_name = Path(pred_path).stem
        # Quitar prefijo "pred_" si existe
        tile_name = pred_name.replace('pred_', '')
        
        # Buscar m√°scara correspondiente con patr√≥n correcto
        mask_path = masks_dir / f"{tile_name.replace('_r', '_mask_r')}.tif"
        
        if not mask_path.exists():
            # Intentar con otros patrones comunes
            alt_patterns = [
                masks_dir / f"{tile_name}_mask.tif",
                masks_dir / f"mask_{tile_name}.tif",
            ]
            for alt_path in alt_patterns:
                if alt_path.exists():
                    mask_path = alt_path
                    break
            else:
                continue  # No se encontr√≥ m√°scara para esta tesela
        
        try:
            # Leer predicci√≥n
            with rasterio.open(pred_path) as src:
                pred = src.read(1)
            
            # Leer m√°scara ground truth
            with rasterio.open(mask_path) as src:
                mask = src.read(1)
            
            # Verificar dimensiones
            if pred.shape != mask.shape:
                print(f"‚ö†Ô∏è Dimensiones no coinciden: {pred_name}")
                skipped_invalid += 1
                invalid_masks.append(f"{tile_name} (dimensiones: pred {pred.shape} vs mask {mask.shape})")
                continue
            
            # ‚≠ê MANEJO DE NaN
            mask_has_nan = np.isnan(mask).any()
            if mask_has_nan:
                # Crear m√°scara de p√≠xeles v√°lidos (no-NaN)
                valid_pixels = ~np.isnan(mask)
                
                # Si toda la m√°scara es NaN, saltarla
                if not valid_pixels.any():
                    skipped_nan += 1
                    nan_masks.append(tile_name)
                    continue
                
                # Filtrar solo p√≠xeles v√°lidos
                mask_clean = mask[valid_pixels]
                pred_clean = pred[valid_pixels]
            else:
                mask_clean = mask.flatten()
                pred_clean = pred.flatten()
            
            # ‚≠ê VERIFICAR SI LA M√ÅSCARA TIENE MANGLAR
            unique_mask_vals = np.unique(mask_clean)
            
            # Saltar m√°scaras vac√≠as (solo 0s)
            if len(unique_mask_vals) == 1 and unique_mask_vals[0] == 0:
                skipped_empty += 1
                empty_masks.append(tile_name)
                continue
            
            # Verificar que la m√°scara sea binaria (0 y 1)
            if not np.all(np.isin(unique_mask_vals, [0, 1])):
                print(f"‚ö†Ô∏è Valores inesperados en {tile_name}: {unique_mask_vals}")
                skipped_invalid += 1
                invalid_masks.append(f"{tile_name} (valores: {unique_mask_vals})")
                continue
            
            # ‚úÖ M√°scara v√°lida: calcular m√©tricas
            TP += np.sum((pred_clean == 1) & (mask_clean == 1))
            TN += np.sum((pred_clean == 0) & (mask_clean == 0))
            FP += np.sum((pred_clean == 1) & (mask_clean == 0))
            FN += np.sum((pred_clean == 0) & (mask_clean == 1))
            
            valid_count += 1
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error procesando {pred_name}: {str(e)}")
            skipped_invalid += 1
            invalid_masks.append(f"{tile_name} (error: {str(e)[:50]})")
            continue
    
    # Mostrar estad√≠sticas de m√°scaras procesadas
    total_processed = valid_count + skipped_empty + skipped_nan + skipped_invalid
    print(f"\nüìä Resumen de procesamiento:")
    print(f"   Total procesado:     {total_processed}")
    print(f"   ‚úÖ M√°scaras v√°lidas:  {valid_count} ({valid_count/total_processed*100:.1f}%)")
    if skipped_empty > 0:
        print(f"   ‚è≠Ô∏è  M√°scaras vac√≠as:  {skipped_empty} ({skipped_empty/total_processed*100:.1f}%) - excluidas correctamente")
    if skipped_nan > 0:
        print(f"   ‚è≠Ô∏è  Con NaN:          {skipped_nan} ({skipped_nan/total_processed*100:.1f}%) - excluidas")
    if skipped_invalid > 0:
        print(f"   ‚ö†Ô∏è  Inv√°lidas:        {skipped_invalid} ({skipped_invalid/total_processed*100:.1f}%) - excluidas")
    
    if valid_count == 0:
        print(f"\n‚ùå No se encontraron m√°scaras v√°lidas con manglar")
        return None, None, 0
    
    print(f"\n‚úÖ Matriz de confusi√≥n calculada con {valid_count} teselas v√°lidas")
    
    # ‚≠ê‚≠ê‚≠ê NUEVO: GUARDAR REPORTE DE M√ÅSCARAS EXCLUIDAS ‚≠ê‚≠ê‚≠ê
    if skipped_empty > 0 or skipped_nan > 0 or skipped_invalid > 0:
        try:
            # Determinar a√±o y directorio de salida
            masks_dir_str = str(masks_dir)
            if 'Manglar_' in masks_dir_str:
                year_match = masks_dir_str.split('Manglar_')[1].split('_')[0]
                report_dir = Path(f'predicciones_por_a√±o/year_{year_match}/metricas')
                report_dir.mkdir(parents=True, exist_ok=True)
                
                excluded_report_path = report_dir / 'mascaras_excluidas.txt'
                
                with open(excluded_report_path, 'w', encoding='utf-8') as f:
                    f.write("="*80 + "\n")
                    f.write("REPORTE DE M√ÅSCARAS EXCLUIDAS DE LA EVALUACI√ìN\n")
                    f.write("="*80 + "\n\n")
                    
                    f.write(f"Total de teselas procesadas:     {total_processed}\n")
                    f.write(f"Teselas v√°lidas (con manglar):   {valid_count} ({valid_count/total_processed*100:.1f}%)\n")
                    f.write(f"Teselas excluidas:               {skipped_empty + skipped_nan + skipped_invalid} ({(skipped_empty + skipped_nan + skipped_invalid)/total_processed*100:.1f}%)\n\n")
                    
                    if skipped_empty > 0:
                        f.write("-"*80 + "\n")
                        f.write(f"1. M√ÅSCARAS VAC√çAS (solo p√≠xeles = 0): {skipped_empty} teselas\n")
                        f.write("-"*80 + "\n")
                        f.write("Raz√≥n: Estas teselas no contienen manglar en el ground truth.\n")
                        f.write("Son √°reas de no-manglar v√°lidas pero no √∫tiles para evaluar la\n")
                        f.write("capacidad del modelo de detectar manglar (solo eval√∫an TN/FP).\n\n")
                        
                        if len(empty_masks) > 0:
                            f.write("Teselas vac√≠as encontradas:\n")
                            for i, mask_name in enumerate(sorted(empty_masks), 1):
                                f.write(f"  {i:3d}. {mask_name}\n")
                            f.write("\n")
                    
                    if skipped_nan > 0:
                        f.write("-"*80 + "\n")
                        f.write(f"2. M√ÅSCARAS CON NaN (valores inv√°lidos): {skipped_nan} teselas\n")
                        f.write("-"*80 + "\n")
                        f.write("Raz√≥n: Estas m√°scaras contienen valores NaN (Not a Number).\n")
                        f.write("Pueden ser m√°scaras corruptas o con problemas de procesamiento.\n\n")
                        
                        if len(nan_masks) > 0:
                            f.write("Teselas con NaN encontradas:\n")
                            for i, mask_name in enumerate(sorted(nan_masks), 1):
                                f.write(f"  {i:3d}. {mask_name}\n")
                            f.write("\n")
                    
                    if skipped_invalid > 0:
                        f.write("-"*80 + "\n")
                        f.write(f"3. M√ÅSCARAS INV√ÅLIDAS (otros problemas): {skipped_invalid} teselas\n")
                        f.write("-"*80 + "\n")
                        f.write("Raz√≥n: Estas m√°scaras tienen problemas como:\n")
                        f.write("  - Dimensiones no coinciden con la predicci√≥n\n")
                        f.write("  - Valores fuera del rango esperado (0, 1)\n")
                        f.write("  - Errores de lectura del archivo\n\n")
                        
                        if len(invalid_masks) > 0:
                            f.write("Teselas inv√°lidas encontradas:\n")
                            for i, mask_info in enumerate(sorted(invalid_masks), 1):
                                f.write(f"  {i:3d}. {mask_info}\n")
                            f.write("\n")
                    
                    f.write("="*80 + "\n")
                    f.write("RECOMENDACIONES:\n")
                    f.write("="*80 + "\n")
                    f.write("1. M√°scaras vac√≠as: NORMAL - √Åreas sin manglar en ground truth.\n")
                    f.write("   ‚Üí No requieren acci√≥n. Son excluidas correctamente.\n\n")
                    f.write("2. M√°scaras con NaN: REVISAR - Archivos posiblemente corruptos.\n")
                    f.write("   ‚Üí Inspeccionar en QGIS o Python para verificar integridad.\n\n")
                    f.write("3. M√°scaras inv√°lidas: INVESTIGAR - Problemas de procesamiento.\n")
                    f.write("   ‚Üí Revisar logs de errores y considerar reprocesar.\n")
                    f.write("="*80 + "\n")
                
                print(f"üìù Reporte de m√°scaras excluidas: {excluded_report_path}")
        
        except Exception as e:
            print(f"‚ö†Ô∏è  No se pudo crear reporte de m√°scaras excluidas: {e}")
    # ‚≠ê‚≠ê‚≠ê FIN DEL REPORTE DE M√ÅSCARAS EXCLUIDAS ‚≠ê‚≠ê‚≠ê
    
    # Construir matriz
    cm = np.array([[TN, FP], [FN, TP]])
    
    # Calcular m√©tricas
    total = TP + TN + FP + FN
    accuracy = (TP + TN) / total if total > 0 else 0
    precision = TP / (TP + FP) if (TP + FP) > 0 else 0
    recall = TP / (TP + FN) if (TP + FN) > 0 else 0
    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0
    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    iou_manglar = TP / (TP + FP + FN) if (TP + FP + FN) > 0 else 0
    iou_no_manglar = TN / (TN + FP + FN) if (TN + FP + FN) > 0 else 0
    mean_iou = (iou_manglar + iou_no_manglar) / 2
    
    metrics = {
        'TP': int(TP),
        'TN': int(TN),
        'FP': int(FP),
        'FN': int(FN),
        'total_pixels': int(total),
        'accuracy': float(accuracy),
        'precision': float(precision),
        'recall': float(recall),
        'specificity': float(specificity),
        'f1_score': float(f1_score),
        'iou_manglar': float(iou_manglar),
        'iou_no_manglar': float(iou_no_manglar),
        'mean_iou': float(mean_iou),
        'tiles_evaluated': valid_count,
        'tiles_skipped_empty': skipped_empty,
        'tiles_skipped_nan': skipped_nan,
        'tiles_skipped_invalid': skipped_invalid
    }
    
    return cm, metrics, valid_count

def plot_confusion_matrix_for_article(cm, metrics, save_path, year):
    """
    Genera matriz de confusi√≥n profesional para art√≠culo cient√≠fico
    """
    
    plt.style.use('seaborn-v0_8-paper')
    fig, ax = plt.subplots(figsize=(10, 8))
    
    # Normalizar a porcentajes
    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100
    
    # Crear heatmap
    im = ax.imshow(cm_percent, interpolation='nearest', cmap='Blues', vmin=0, vmax=100)
    
    # Colorbar
    cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
    cbar.set_label('Porcentaje (%)', rotation=270, labelpad=25, fontsize=13)
    cbar.ax.tick_params(labelsize=11)
    
    # Etiquetas de clases
    classes = ['No Manglar', 'Manglar']
    tick_marks = np.arange(len(classes))
    ax.set_xticks(tick_marks)
    ax.set_yticks(tick_marks)
    ax.set_xticklabels(classes, fontsize=13)
    ax.set_yticklabels(classes, fontsize=13)
    
    # Valores en celdas
    thresh = cm_percent.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            text_main = f'{cm_percent[i, j]:.1f}%'
            text_count = f'({cm[i, j]:,} px)'
            
            color = "white" if cm_percent[i, j] > thresh else "black"
            
            ax.text(j, i - 0.15, text_main,
                   ha="center", va="center", color=color,
                   fontsize=18, fontweight='bold')
            
            ax.text(j, i + 0.15, text_count,
                   ha="center", va="center", color=color,
                   fontsize=11)
    
    # Etiquetas TN, FP, FN, TP
    annotations = [('TN', 0, 0), ('FP', 1, 0), ('FN', 0, 1), ('TP', 1, 1)]
    for label, x, y in annotations:
        ax.text(x, y - 0.42, label,
               ha="center", va="center",
               color="red", fontsize=11, fontweight='bold',
               bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.4))
    
    # Etiquetas de ejes
    ax.set_ylabel('Clase Real (Ground Truth)', fontsize=14, fontweight='bold')
    ax.set_xlabel('Clase Predicha', fontsize=14, fontweight='bold')
    
    # T√≠tulo con m√©tricas principales y a√±o
    title = f'Matriz de Confusi√≥n - A√±o {year}\n'
    title += f'Accuracy: {metrics["accuracy"]*100:.2f}% | '
    title += f'F1-Score: {metrics["f1_score"]:.4f} | '
    title += f'IoU: {metrics["mean_iou"]:.4f}\n'
    title += f'({metrics["tiles_evaluated"]} teselas evaluadas)'
    
    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)
    
    # Grid sutil
    ax.set_xticks(np.arange(cm.shape[1]+1)-.5, minor=True)
    ax.set_yticks(np.arange(cm.shape[0]+1)-.5, minor=True)
    ax.grid(which="minor", color="gray", linestyle='-', linewidth=2)
    ax.tick_params(which="minor", size=0)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"‚úÖ Matriz de confusi√≥n guardada: {save_path}")


def plot_metrics_comparison(metrics, save_path, year):
    """
    Crea un gr√°fico de barras con todas las m√©tricas
    """
    
    plt.style.use('seaborn-v0_8-paper')
    fig, ax = plt.subplots(figsize=(12, 7))
    
    # M√©tricas a graficar
    metric_names = ['Accuracy', 'Precision', 'Recall', 'Specificity', 'F1-Score', 'Mean IoU']
    metric_values = [
        metrics['accuracy'],
        metrics['precision'],
        metrics['recall'],
        metrics['specificity'],
        metrics['f1_score'],
        metrics['mean_iou']
    ]
    
    # Colores seg√∫n rendimiento
    colors = []
    for val in metric_values:
        if val >= 0.95:
            colors.append('#2ecc71')  # Verde - Excelente
        elif val >= 0.90:
            colors.append('#3498db')  # Azul - Muy bueno
        elif val >= 0.80:
            colors.append('#f39c12')  # Naranja - Bueno
        else:
            colors.append('#e74c3c')  # Rojo - Mejorable
    
    # Crear barras
    bars = ax.barh(metric_names, metric_values, color=colors, edgecolor='black', linewidth=1.5)
    
    # A√±adir valores al final de cada barra
    for i, (bar, val) in enumerate(zip(bars, metric_values)):
        ax.text(val + 0.01, i, f'{val:.4f}\n({val*100:.2f}%)',
               va='center', fontsize=11, fontweight='bold')
    
    # L√≠nea de referencia en 0.90
    ax.axvline(x=0.90, color='red', linestyle='--', linewidth=2, alpha=0.5, label='Umbral 90%')
    
    # Configuraci√≥n de ejes
    ax.set_xlim(0, 1.05)
    ax.set_xlabel('Valor de la M√©trica', fontsize=13, fontweight='bold')
    ax.set_title(f'M√©tricas de Rendimiento del Modelo - A√±o {year}\n' +
                 f'({metrics["tiles_evaluated"]} teselas evaluadas)',
                 fontsize=14, fontweight='bold', pad=20)
    
    # Grid
    ax.grid(axis='x', alpha=0.3, linestyle='--')
    ax.legend(fontsize=11)
    
    # Aumentar tama√±o de etiquetas
    ax.tick_params(axis='both', labelsize=12)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"‚úÖ Gr√°fico de m√©tricas guardado: {save_path}")


def save_confusion_matrix_report(cm, metrics, save_path, year):
    """
    Genera reporte de texto detallado
    """
    
    with open(save_path, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write(f"MATRIZ DE CONFUSI√ìN Y M√âTRICAS - A√ëO {year}\n")
        f.write("="*80 + "\n\n")
        
        f.write("INFORMACI√ìN GENERAL:\n")
        f.write("-"*80 + "\n")
        f.write(f"A√±o de an√°lisis:        {year}\n")
        f.write(f"Teselas evaluadas:      {metrics['tiles_evaluated']}\n")
        f.write(f"Total de p√≠xeles:       {metrics['total_pixels']:,}\n")
        f.write("-"*80 + "\n\n")
        
        f.write("MATRIZ DE CONFUSI√ìN:\n")
        f.write("-"*80 + "\n")
        f.write(f"                    Predicho No-Manglar    Predicho Manglar\n")
        f.write(f"Real No-Manglar     {cm[0,0]:>18,} (TN)    {cm[0,1]:>15,} (FP)\n")
        f.write(f"Real Manglar        {cm[1,0]:>18,} (FN)    {cm[1,1]:>15,} (TP)\n")
        f.write("-"*80 + "\n\n")
        
        f.write("CONTEOS ABSOLUTOS:\n")
        f.write("-"*80 + "\n")
        f.write(f"True Positives (TP):    {metrics['TP']:>18,} p√≠xeles\n")
        f.write(f"True Negatives (TN):    {metrics['TN']:>18,} p√≠xeles\n")
        f.write(f"False Positives (FP):   {metrics['FP']:>18,} p√≠xeles\n")
        f.write(f"False Negatives (FN):   {metrics['FN']:>18,} p√≠xeles\n")
        f.write("-"*80 + "\n\n")
        
        f.write("M√âTRICAS DE RENDIMIENTO:\n")
        f.write("-"*80 + "\n")
        f.write(f"Accuracy:               {metrics['accuracy']:>10.6f}  ({metrics['accuracy']*100:>6.2f}%)\n")
        f.write(f"Precision:              {metrics['precision']:>10.6f}  ({metrics['precision']*100:>6.2f}%)\n")
        f.write(f"Recall (Sensitivity):   {metrics['recall']:>10.6f}  ({metrics['recall']*100:>6.2f}%)\n")
        f.write(f"Specificity:            {metrics['specificity']:>10.6f}  ({metrics['specificity']*100:>6.2f}%)\n")
        f.write(f"F1-Score:               {metrics['f1_score']:>10.6f}\n")
        f.write("-"*80 + "\n\n")
        
        f.write("M√âTRICAS DE SEGMENTACI√ìN (IoU):\n")
        f.write("-"*80 + "\n")
        f.write(f"IoU Manglar:            {metrics['iou_manglar']:>10.6f}\n")
        f.write(f"IoU No-Manglar:         {metrics['iou_no_manglar']:>10.6f}\n")
        f.write(f"Mean IoU:               {metrics['mean_iou']:>10.6f}\n")
        f.write("-"*80 + "\n\n")
        
        # Calcular tasas de error
        fpr = metrics['FP'] / (metrics['FP'] + metrics['TN']) if (metrics['FP'] + metrics['TN']) > 0 else 0
        fnr = metrics['FN'] / (metrics['FN'] + metrics['TP']) if (metrics['FN'] + metrics['TP']) > 0 else 0
        
        f.write("AN√ÅLISIS DE ERRORES:\n")
        f.write("-"*80 + "\n")
        f.write(f"Tasa de Falsos Positivos (FPR):  {fpr*100:>6.2f}%\n")
        f.write(f"  ‚Üí De cada 100 p√≠xeles de no-manglar, {fpr*100:.1f} son clasificados\n")
        f.write(f"    incorrectamente como manglar\n\n")
        f.write(f"Tasa de Falsos Negativos (FNR):   {fnr*100:>6.2f}%\n")
        f.write(f"  ‚Üí De cada 100 p√≠xeles de manglar, {fnr*100:.1f} NO son detectados\n\n")
        f.write("-"*80 + "\n\n")
        
        f.write("INTERPRETACI√ìN:\n")
        f.write("-"*80 + "\n")
        f.write(f"‚Ä¢ El modelo clasifica correctamente el {metrics['accuracy']*100:.2f}% de los p√≠xeles\n\n")
        f.write(f"‚Ä¢ Precision ({metrics['precision']*100:.2f}%):\n")
        f.write(f"  Cuando el modelo predice 'Manglar', acierta {metrics['precision']*100:.1f}%\n")
        f.write(f"  de las veces\n\n")
        f.write(f"‚Ä¢ Recall ({metrics['recall']*100:.2f}%):\n")
        f.write(f"  El modelo detecta {metrics['recall']*100:.1f}% de todo el manglar presente\n\n")
        f.write(f"‚Ä¢ F1-Score ({metrics['f1_score']:.4f}):\n")
        f.write(f"  Balance arm√≥nico entre Precision y Recall\n\n")
        f.write(f"‚Ä¢ Mean IoU ({metrics['mean_iou']:.4f}):\n")
        
        if metrics['mean_iou'] >= 0.90:
            f.write(f"  ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê EXCELENTE - Rendimiento excepcional\n")
        elif metrics['mean_iou'] >= 0.80:
            f.write(f"  ‚≠ê‚≠ê‚≠ê‚≠ê MUY BUENO - Rendimiento por encima del promedio\n")
        elif metrics['mean_iou'] >= 0.70:
            f.write(f"  ‚≠ê‚≠ê‚≠ê BUENO - Rendimiento aceptable\n")
        else:
            f.write(f"  ‚≠ê‚≠ê MEJORABLE - Considerar refinamiento del modelo\n")
        
        f.write("\n" + "="*80 + "\n")
    
    print(f"‚úÖ Reporte detallado guardado: {save_path}")


def generate_advanced_analysis_plots(predictions_dir, masks_dir, output_dir, year, threshold=0.5):
    """
    Genera gr√°ficos de an√°lisis avanzados incluyendo curva ROC

    Args:
        predictions_dir: Directorio con predicciones GeoTIFF
        masks_dir: Directorio con m√°scaras ground truth
        output_dir: Directorio de salida para gr√°ficos
        year: A√±o de an√°lisis
        threshold: Umbral de decisi√≥n para binarizaci√≥n

    Returns:
        Dict con m√©tricas calculadas
    """

    print(f"\nüìä Generando gr√°ficos de an√°lisis avanzados...")

    # Buscar archivos de predicci√≥n
    pred_files = sorted(predictions_dir.glob("pred_*.tif"))

    if len(pred_files) == 0:
        print(f"‚ö†Ô∏è No se encontraron predicciones")
        return None

    # Recolectar datos de todas las teselas
    tiles_data = []
    all_probs = []  # Para curva ROC
    all_labels = []  # Para curva ROC

    print(f"   Analizando {len(pred_files)} teselas...")

    for pred_path in tqdm(pred_files, desc="Calculando m√©tricas por tesela"):
        pred_name = pred_path.stem
        tile_name = pred_name.replace('pred_', '')

        # Buscar m√°scara correspondiente
        mask_path = masks_dir / f"{tile_name.replace('_r', '_mask_r')}.tif"
        if not mask_path.exists():
            alt_patterns = [
                masks_dir / f"{tile_name}_mask.tif",
                masks_dir / f"mask_{tile_name}.tif",
            ]
            for alt_path in alt_patterns:
                if alt_path.exists():
                    mask_path = alt_path
                    break
            else:
                continue

        try:
            # Leer predicci√≥n (probabilidades o binario)
            with rasterio.open(pred_path) as src:
                pred = src.read(1)

            # Leer m√°scara
            with rasterio.open(mask_path) as src:
                mask = src.read(1)

            if pred.shape != mask.shape:
                continue

            # Filtrar p√≠xeles v√°lidos
            valid_pixels = ~np.isnan(mask) & ~np.isnan(pred)
            mask_clean = mask[valid_pixels]
            pred_clean = pred[valid_pixels]

            # Saltar m√°scaras vac√≠as
            if len(np.unique(mask_clean)) == 1 and np.unique(mask_clean)[0] == 0:
                continue

            if len(mask_clean) == 0:
                continue

            # Calcular m√©tricas por tesela
            TP = np.sum((pred_clean == 1) & (mask_clean == 1))
            TN = np.sum((pred_clean == 0) & (mask_clean == 0))
            FP = np.sum((pred_clean == 1) & (mask_clean == 0))
            FN = np.sum((pred_clean == 0) & (mask_clean == 1))

            tile_iou = TP / (TP + FP + FN) if (TP + FP + FN) > 0 else 0.0
            tile_acc = (TP + TN) / len(mask_clean) if len(mask_clean) > 0 else 0.0

            cobertura_real = (mask_clean == 1).sum() / len(mask_clean) * 100
            cobertura_pred = (pred_clean == 1).sum() / len(pred_clean) * 100

            tiles_data.append({
                'tile_name': tile_name,
                'iou': tile_iou,
                'accuracy': tile_acc,
                'cobertura_real': cobertura_real,
                'cobertura_pred': cobertura_pred,
                'TP': TP,
                'TN': TN,
                'FP': FP,
                'FN': FN,
            })

            # Acumular para curva ROC (usando predicciones como "probabilidades")
            # Nota: Si pred ya es binario (0/1), ROC ser√° escalonada
            # Si es continuo [0,1], ROC ser√° suave
            all_probs.extend(pred_clean)
            all_labels.extend(mask_clean)

        except Exception as e:
            continue

    if len(tiles_data) == 0:
        print(f"‚ö†Ô∏è No se pudieron analizar teselas")
        return None

    # Extraer listas
    ious = [t['iou'] for t in tiles_data]
    accuracies = [t['accuracy'] for t in tiles_data]
    real_cov = [t['cobertura_real'] for t in tiles_data]
    pred_cov = [t['cobertura_pred'] for t in tiles_data]
    diff_cov = [t['cobertura_pred'] - t['cobertura_real'] for t in tiles_data]

    # ========================================================================
    # FIGURA 1: An√°lisis de m√©tricas (4 subplots)
    # ========================================================================

    fig1, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig1.suptitle(f'An√°lisis de M√©tricas - A√±o {year}', fontsize=16, fontweight='bold', y=0.995)

    # Subplot 1: Histograma de IoU
    axes[0, 0].hist(ious, bins=20, color='steelblue', edgecolor='black', alpha=0.7)
    mean_iou = np.mean(ious)
    axes[0, 0].axvline(mean_iou, color='red', linestyle='--', linewidth=2,
                      label=f'Media: {mean_iou:.4f}')
    axes[0, 0].set_xlabel('IoU', fontsize=11, fontweight='bold')
    axes[0, 0].set_ylabel('Cantidad de Teselas', fontsize=11, fontweight='bold')
    axes[0, 0].set_title('Distribuci√≥n de IoU', fontsize=12, fontweight='bold')
    axes[0, 0].legend(fontsize=10)
    axes[0, 0].grid(alpha=0.3)

    # Subplot 2: Scatter - Cobertura Real vs Predicha
    scatter = axes[0, 1].scatter(real_cov, pred_cov, alpha=0.6, c=ious, cmap='RdYlGn',
                                 edgecolors='black', s=50, vmin=0, vmax=1)
    axes[0, 1].plot([0, 100], [0, 100], 'r--', linewidth=2, label='Predicci√≥n perfecta')
    axes[0, 1].set_xlabel('Cobertura Real (%)', fontsize=11, fontweight='bold')
    axes[0, 1].set_ylabel('Cobertura Predicha (%)', fontsize=11, fontweight='bold')
    axes[0, 1].set_title('Cobertura: Real vs Predicha', fontsize=12, fontweight='bold')
    axes[0, 1].legend(fontsize=10)
    axes[0, 1].grid(alpha=0.3)
    cbar = plt.colorbar(scatter, ax=axes[0, 1])
    cbar.set_label('IoU', fontsize=10)

    # Subplot 3: Box plot de IoU
    bp = axes[1, 0].boxplot(ious, vert=True, patch_artist=True,
                            boxprops=dict(facecolor='lightblue', color='black'),
                            medianprops=dict(color='red', linewidth=2),
                            whiskerprops=dict(color='black', linewidth=1.5),
                            capprops=dict(color='black', linewidth=1.5))
    axes[1, 0].set_ylabel('IoU', fontsize=11, fontweight='bold')
    axes[1, 0].set_title('Distribuci√≥n de IoU (Box Plot)', fontsize=12, fontweight='bold')
    axes[1, 0].grid(alpha=0.3, axis='y')

    # A√±adir estad√≠sticas al box plot
    q1, median, q3 = np.percentile(ious, [25, 50, 75])
    iqr = q3 - q1
    axes[1, 0].text(1.15, median, f'Mediana: {median:.4f}', fontsize=9, va='center')
    axes[1, 0].text(1.15, q3, f'Q3: {q3:.4f}', fontsize=9, va='center')
    axes[1, 0].text(1.15, q1, f'Q1: {q1:.4f}', fontsize=9, va='center')

    # Subplot 4: Histograma de error en cobertura
    axes[1, 1].hist(diff_cov, bins=20, color='coral', edgecolor='black', alpha=0.7)
    axes[1, 1].axvline(0, color='green', linestyle='--', linewidth=2, label='Sin error')
    mean_diff = np.mean(diff_cov)
    axes[1, 1].axvline(mean_diff, color='red', linestyle='--', linewidth=2,
                      label=f'Error medio: {mean_diff:.2f}%')
    axes[1, 1].set_xlabel('Diferencia Cobertura (Pred - Real) %', fontsize=11, fontweight='bold')
    axes[1, 1].set_ylabel('Cantidad de Teselas', fontsize=11, fontweight='bold')
    axes[1, 1].set_title('Error en Estimaci√≥n de Cobertura', fontsize=12, fontweight='bold')
    axes[1, 1].legend(fontsize=10)
    axes[1, 1].grid(alpha=0.3)

    plt.tight_layout()
    analysis_path = output_dir / f'analisis_metricas_{year}.png'
    plt.savefig(analysis_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    print(f"   ‚úÖ Gr√°ficos de an√°lisis guardados: {analysis_path.name}")

    # ========================================================================
    # FIGURA 2: Curva ROC (Receiver Operating Characteristic)
    # ========================================================================

    print(f"   Calculando curva ROC...")

    # Convertir a numpy arrays
    all_probs = np.array(all_probs)
    all_labels = np.array(all_labels).astype(int)

    # Calcular curva ROC
    from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score

    # ROC curve
    fpr, tpr, thresholds_roc = roc_curve(all_labels, all_probs)
    roc_auc = auc(fpr, tpr)

    # Precision-Recall curve
    precision, recall, thresholds_pr = precision_recall_curve(all_labels, all_probs)
    avg_precision = average_precision_score(all_labels, all_probs)

    # Encontrar threshold √≥ptimo (punto m√°s cercano a (0,1) en ROC)
    distances = np.sqrt((fpr - 0)**2 + (tpr - 1)**2)
    optimal_idx = np.argmin(distances)
    optimal_threshold_roc = thresholds_roc[optimal_idx]
    optimal_fpr = fpr[optimal_idx]
    optimal_tpr = tpr[optimal_idx]

    # Encontrar threshold √≥ptimo seg√∫n F1-score
    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)
    optimal_idx_f1 = np.argmax(f1_scores)
    if optimal_idx_f1 < len(thresholds_pr):
        optimal_threshold_f1 = thresholds_pr[optimal_idx_f1]
    else:
        optimal_threshold_f1 = threshold

    # Crear figura con 2 subplots
    fig2, axes = plt.subplots(1, 2, figsize=(14, 6))
    fig2.suptitle(f'Curvas de Evaluaci√≥n del Modelo - A√±o {year}', fontsize=16, fontweight='bold')

    # Subplot 1: Curva ROC
    axes[0].plot(fpr, tpr, color='darkblue', lw=2, label=f'ROC (AUC = {roc_auc:.4f})')
    axes[0].plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', label='Clasificador aleatorio')
    axes[0].scatter([optimal_fpr], [optimal_tpr], color='red', s=100, zorder=5,
                   label=f'√ìptimo (thr={optimal_threshold_roc:.3f})')
    axes[0].set_xlim([0.0, 1.0])
    axes[0].set_ylim([0.0, 1.05])
    axes[0].set_xlabel('False Positive Rate (FPR)', fontsize=12, fontweight='bold')
    axes[0].set_ylabel('True Positive Rate (TPR)', fontsize=12, fontweight='bold')
    axes[0].set_title('Curva ROC\n(Capacidad de discriminaci√≥n)', fontsize=13, fontweight='bold')
    axes[0].legend(loc='lower right', fontsize=10)
    axes[0].grid(alpha=0.3)

    # A√±adir texto explicativo
    text_roc = (f"AUC = {roc_auc:.4f}\n"
                f"TPR √≥ptimo = {optimal_tpr:.3f}\n"
                f"FPR √≥ptimo = {optimal_fpr:.3f}")
    axes[0].text(0.6, 0.2, text_roc, fontsize=10, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    # Subplot 2: Precision-Recall curve
    axes[1].plot(recall, precision, color='darkgreen', lw=2,
                label=f'PR (AP = {avg_precision:.4f})')
    axes[1].axhline(y=all_labels.mean(), color='gray', linestyle='--', lw=2,
                   label=f'Baseline (prevalencia={all_labels.mean():.3f})')
    axes[1].set_xlim([0.0, 1.0])
    axes[1].set_ylim([0.0, 1.05])
    axes[1].set_xlabel('Recall (Sensibilidad)', fontsize=12, fontweight='bold')
    axes[1].set_ylabel('Precision', fontsize=12, fontweight='bold')
    axes[1].set_title('Curva Precision-Recall\n(Balance detecci√≥n vs falsos positivos)', fontsize=13, fontweight='bold')
    axes[1].legend(loc='lower left', fontsize=10)
    axes[1].grid(alpha=0.3)

    # A√±adir texto explicativo
    text_pr = (f"AP = {avg_precision:.4f}\n"
               f"Threshold F1 = {optimal_threshold_f1:.3f}")
    axes[1].text(0.6, 0.9, text_pr, fontsize=10, bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))

    plt.tight_layout()
    roc_path = output_dir / f'curva_roc_{year}.png'
    plt.savefig(roc_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    print(f"   ‚úÖ Curva ROC guardada: {roc_path.name}")

    # ========================================================================
    # FIGURA 3: Casos destacados (mejores y peores)
    # ========================================================================

    # Ordenar por IoU
    tiles_sorted = sorted(tiles_data, key=lambda x: x['iou'], reverse=True)

    best_5 = tiles_sorted[:5]
    worst_5 = tiles_sorted[-5:]

    fig3, axes = plt.subplots(2, 1, figsize=(12, 8))
    fig3.suptitle(f'Casos Destacados - A√±o {year}', fontsize=16, fontweight='bold', y=0.995)

    # Mejores casos
    best_names = [t['tile_name'][:20] + '...' if len(t['tile_name']) > 20 else t['tile_name'] for t in best_5]
    best_ious = [t['iou'] for t in best_5]

    axes[0].barh(range(len(best_5)), best_ious, color='green', alpha=0.7, edgecolor='black')
    axes[0].set_yticks(range(len(best_5)))
    axes[0].set_yticklabels(best_names, fontsize=9)
    axes[0].set_xlabel('IoU', fontsize=11, fontweight='bold')
    axes[0].set_title('üèÜ Top 5 Teselas (Mayor IoU)', fontsize=12, fontweight='bold', color='darkgreen')
    axes[0].set_xlim([0, 1])
    axes[0].grid(alpha=0.3, axis='x')

    for i, (iou, tile) in enumerate(zip(best_ious, best_5)):
        axes[0].text(iou + 0.01, i, f'{iou:.4f}', va='center', fontsize=9, fontweight='bold')

    # Peores casos
    worst_names = [t['tile_name'][:20] + '...' if len(t['tile_name']) > 20 else t['tile_name'] for t in worst_5]
    worst_ious = [t['iou'] for t in worst_5]

    axes[1].barh(range(len(worst_5)), worst_ious, color='red', alpha=0.7, edgecolor='black')
    axes[1].set_yticks(range(len(worst_5)))
    axes[1].set_yticklabels(worst_names, fontsize=9)
    axes[1].set_xlabel('IoU', fontsize=11, fontweight='bold')
    axes[1].set_title('‚ö†Ô∏è Bottom 5 Teselas (Menor IoU)', fontsize=12, fontweight='bold', color='darkred')
    axes[1].set_xlim([0, 1])
    axes[1].grid(alpha=0.3, axis='x')

    for i, (iou, tile) in enumerate(zip(worst_ious, worst_5)):
        axes[1].text(iou + 0.01, i, f'{iou:.4f}', va='center', fontsize=9, fontweight='bold')

    plt.tight_layout()
    casos_path = output_dir / f'casos_destacados_{year}.png'
    plt.savefig(casos_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    print(f"   ‚úÖ Casos destacados guardados: {casos_path.name}")

    # Retornar m√©tricas calculadas
    return {
        'num_tiles': len(tiles_data),
        'mean_iou': mean_iou,
        'mean_accuracy': np.mean(accuracies),
        'roc_auc': roc_auc,
        'avg_precision': avg_precision,
        'optimal_threshold_roc': optimal_threshold_roc,
        'optimal_threshold_f1': optimal_threshold_f1,
        'best_tiles': best_5,
        'worst_tiles': worst_5,
    }


#====================================
# FUNCIONES DEL PIPELINE
#====================================

def load_model(checkpoint_path, device='cpu'):
    """
    Carga el modelo entrenado desde un checkpoint.

    Detecta autom√°ticamente si es un modelo MultiBranch o UnetPlusPlus est√°ndar
    bas√°ndose en las claves del state_dict.

    Tambi√©n detecta si el modelo usa m√≥dulos de atenci√≥n (scSE).
    """
    print(f"üì¶ Cargando modelo desde: {checkpoint_path}")

    checkpoint = torch.load(checkpoint_path, map_location=device)
    state_dict = {k.replace('model.', ''): v for k, v in checkpoint['state_dict'].items()}

    # Detectar tipo de modelo bas√°ndose en las claves del state_dict
    is_multibranch = any('high_res_encoder' in key for key in state_dict.keys())

    # Detectar si el modelo tiene m√≥dulos de atenci√≥n
    has_attention = any('attention' in key and ('cSE' in key or 'sSE' in key) for key in state_dict.keys())

    if is_multibranch:
        print(f"üîç Detectado: Modelo Multi-Branch UNet++")
        print(f"   - Arquitectura: Dual encoder (high-res + low-res)")
        print(f"   - Fusion: FPN (Feature Pyramid Network)")
        print(f"   - Decoder: UNet++ con nested skip connections")

        if has_attention:
            print(f"   - Atenci√≥n: scSE (Spatial and Channel Squeeze & Excitation)")
            attention_type = 'scse'
        else:
            print(f"   - Atenci√≥n: None")
            attention_type = None

        # Crear modelo MultiBranch
        wrapper = MultiBranchUNetWrapper(
            encoder_name='resnet101',
            encoder_weights=None,  # Los pesos ya est√°n en el checkpoint
            high_res_channels=4,   # B2, B3, B4, B8 (10m)
            low_res_channels=2,    # B11, B12 (20m)
            num_classes=1,
            fusion_mode='fpn',
            upsample_mode='bilinear',
            deep_supervision=False,
            attention_type=attention_type  # Detectado autom√°ticamente
        )

        # Cargar pesos del checkpoint
        # El wrapper tiene un atributo 'model' que contiene el MultiBranchUNet
        # Las claves del checkpoint no tienen el prefijo "model." porque ya lo quitamos
        wrapper.model.load_state_dict(state_dict, strict=True)
        model = wrapper

    else:
        print(f"üîç Detectado: Modelo UNet++ est√°ndar")
        print(f"   - Arquitectura: Single encoder")
        print(f"   - Decoder: UNet++")

        # Crear modelo UNet++ est√°ndar
        model = smp.UnetPlusPlus(encoder_name='resnet34', in_channels=6)
        model.load_state_dict(state_dict)

    # Envolver en Module (para compatibilidad con el resto del c√≥digo)
    module = Module(model)
    module.to(device)
    module.eval()

    print(f"‚úÖ Modelo cargado exitosamente")
    return module


def predict_tile(module, image_path, device='cpu', threshold=0.20):
    """
    Realiza predicci√≥n en una tesela individual
    
    ‚úÖ OPTIMIZADO: Sin re-normalizaci√≥n (im√°genes ya vienen [0,1] desde GEE)
    
    Args:
        module: Modelo cargado
        image_path: Ruta a la imagen .tif
        device: Dispositivo ('cpu', 'cuda', 'mps')
        threshold: Umbral de decisi√≥n (0.0-1.0)
    
    Returns:
        pred_binary: Predicci√≥n binaria (0, 1)
        profile: Perfil de rasterio
        transform: Transformaci√≥n geoespacial
        bounds: L√≠mites espaciales
        crs: Sistema de coordenadas
    
    Notas:
        - Las im√°genes Sentinel-2 ya est√°n normalizadas [0, 1] desde GEE
        - NO se aplica normalizaci√≥n percentil adicional (evita compresi√≥n de rango)
        - Threshold 0.20 optimizado para este preprocesamiento
    """
    with rasterio.open(image_path) as src:
        image = src.read()
        profile = src.profile.copy()
        transform = src.transform
        bounds = src.bounds
        crs = src.crs
        
        # ‚≠ê PREPROCESAMIENTO SIMPLIFICADO ‚≠ê
        # Solo convertir a float32 y asegurar rango [0, 1]
        image = image.astype(np.float32)
        image = np.clip(image, 0, 1)
        
        # Convertir a tensor
        image_tensor = torch.from_numpy(image).unsqueeze(0).to(device)
        
        # Predicci√≥n
        with torch.no_grad():
            logits = module.model(image_tensor)
            probs = torch.sigmoid(logits)
        
        pred_np = probs.squeeze().cpu().numpy()
        pred_binary = (pred_np > threshold).astype(np.uint8)
    
    return pred_binary, profile, transform, bounds, crs


#====================================
# ‚≠ê‚≠ê‚≠ê NUEVA FUNCI√ìN: POST-PROCESAMIENTO MORFOL√ìGICO ‚≠ê‚≠ê‚≠ê
#====================================

def post_process_mangrove_prediction(pred_binary, mode='conservative'):
    """
    Post-procesamiento morfol√≥gico para segmentaci√≥n de manglar
    
    Basado en literatura cient√≠fica:
    - Pham & Yoshino (2016) Remote Sensing of Environment
    - Chen et al. (2020) ISPRS Journal  
    - Wang et al. (2023) Remote Sensing of Environment
    
    Justificaci√≥n ecol√≥gica:
    Los manglares crecen en parches continuos debido a crecimiento lateral 
    de ra√≠ces y propagaci√≥n clonal (Tomlinson, 2016). Las discontinuidades 
    en predicciones del modelo reflejan variabilidad espectral interna 
    (sombras, diferentes especies) m√°s que fragmentaci√≥n real del manglar.
    
    Operaciones morfol√≥gicas:
    - Closing: Rellena peque√±os huecos dentro de objetos (dilataci√≥n + erosi√≥n)
    - Opening: Elimina ruido aislado (erosi√≥n + dilataci√≥n)
    
    Args:
        pred_binary: Predicci√≥n binaria (0, 1) como numpy array 2D
        mode: Modo de post-procesamiento
            'conservative' - Kernel 3x3, cambio m√≠nimo (recomendado para tesis)
            'moderate'     - Kernel 5x5, m√°s correcci√≥n (validado en literatura)
            'none'         - Sin post-procesamiento (para comparaci√≥n)
    
    Returns:
        Predicci√≥n refinada (numpy array uint8)
    
    Referencias:
        Pham, T. D., & Yoshino, K. (2016). Mangrove mapping and change 
        detection using multi-temporal Landsat imagery. Remote Sensing 
        of Environment, 175, 175-185.
        
        Chen, Y., et al. (2020). Deep learning for forest mapping from 
        satellite imagery. ISPRS Journal, 166, 195-213.
        
        Wang, L., et al. (2023). Deep learning-based mangrove mapping. 
        Remote Sensing of Environment, 285, 113123.
        
        Tomlinson, P. B. (2016). The Botany of Mangroves. Cambridge 
        University Press.
    """
    
    if mode == 'conservative':
        # Kernel peque√±o (3x3) - Cambio m√≠nimo, cient√≠ficamente conservador
        # Cierra huecos de hasta 9 p√≠xeles (3x3)
        kernel = np.ones((3, 3), dtype=np.uint8)
        
        # Paso 1: Closing - cierra peque√±os huecos dentro de parches
        pred_closed = binary_closing(pred_binary, structure=kernel)
        
        # Paso 2: Opening - elimina p√≠xeles aislados (ruido)
        pred_final = binary_opening(pred_closed, structure=kernel)
        
    elif mode == 'moderate':
        # Kernel mediano (5x5) - M√°s correcci√≥n, validado en Pham & Yoshino (2016)
        # Cierra huecos de hasta 25 p√≠xeles (5x5)
        kernel_close = np.ones((5, 5), dtype=np.uint8)
        kernel_open = np.ones((3, 3), dtype=np.uint8)
        
        pred_closed = binary_closing(pred_binary, structure=kernel_close)
        pred_final = binary_opening(pred_closed, structure=kernel_open)
        
    elif mode == 'none':
        # Sin post-procesamiento (para comparaci√≥n en tesis)
        pred_final = pred_binary
        
    else:
        raise ValueError(f"Modo '{mode}' no v√°lido. Usar: 'conservative', 'moderate', o 'none'")
    
    return pred_final.astype(np.uint8)


def save_prediction_geotiff(pred_binary, profile, transform, save_path):
    """
    Guarda la predicci√≥n como GeoTIFF georreferenciado
    
    ‚úÖ CORREGIDO: Fuerza eliminaci√≥n del archivo antes de escribir
    """
    from pathlib import Path
    import os
    
    # ‚≠ê FORZAR ELIMINACI√ìN SI EXISTE
    save_path_obj = Path(save_path)
    if save_path_obj.exists():
        try:
            os.remove(save_path)
        except Exception as e:
            print(f"‚ö†Ô∏è No se pudo eliminar {save_path}: {e}")
    
    profile.update(
        count=1,
        dtype='uint8',
        compress='lzw',
        nodata=255,
        transform=transform
    )
    
    with rasterio.open(save_path, 'w', **profile) as dst:
        dst.write(pred_binary, 1)
        dst.write_colormap(1, {
            0: (139, 69, 19),
            1: (34, 139, 34),
            255: (0, 0, 0)
        })


def process_tiles(checkpoint_path, images_dir, output_dir, device='cpu', threshold=0.20, 
                  use_postproc=True, postproc_mode='conservative'):
    """
    Procesa todas las teselas del directorio de im√°genes
    
    ‚úÖ OPTIMIZADO: Sin normalizaci√≥n percentil redundante
    
    Args:
        checkpoint_path: Ruta al modelo entrenado (.ckpt)
        images_dir: Directorio con im√°genes (.tif)
        output_dir: Directorio de salida para predicciones
        device: Dispositivo de c√≥mputo ('cpu', 'cuda', 'mps')
        threshold: Umbral de decisi√≥n (0.0-1.0)
        use_postproc: Activar post-procesamiento morfol√≥gico (recomendado: True)
        postproc_mode: Modo de post-procesamiento ('conservative', 'moderate', 'none')
    
    Returns:
        Lista de rutas a archivos de predicci√≥n generados
    """
    
    module = load_model(checkpoint_path, device)
    
    # Buscar todos los .tif en el directorio
    tile_paths = sorted(images_dir.glob("*.tif"))
    
    if len(tile_paths) == 0:
        raise ValueError(f"‚ùå No se encontraron archivos .tif en {images_dir}")
    
    print(f"\nüîç Encontradas {len(tile_paths)} teselas en {images_dir}")
    
    pred_files = []
    
    # ‚≠ê MENSAJE INFORMATIVO SOBRE CONFIGURACI√ìN
    postproc_status = "ACTIVADO" if use_postproc else "DESACTIVADO"
    print(f"\nüöÄ Iniciando predicci√≥n de teselas")
    print(f"   Umbral de decisi√≥n: {threshold}")
    print(f"   Preprocesamiento: SIN normalizaci√≥n adicional (im√°genes ya en [0,1])")
    print(f"   Post-procesamiento morfol√≥gico: {postproc_status}")
    if use_postproc:
        kernel_size = '3x3' if postproc_mode == 'conservative' else '5x5' if postproc_mode == 'moderate' else 'N/A'
        print(f"   Modo: {postproc_mode} (kernel {kernel_size})")
        print(f"   Referencia: Pham & Yoshino (2016), Wang et al. (2023)")
    
    for tile_path in tqdm(tile_paths, desc="Prediciendo teselas"):
        try:
            # Predicci√≥n base
            pred_binary, profile, transform, bounds, crs = predict_tile(
                module, str(tile_path), device, threshold
            )
            
            # ‚≠ê‚≠ê‚≠ê APLICAR POST-PROCESAMIENTO MORFOL√ìGICO ‚≠ê‚≠ê‚≠ê
            if use_postproc:
                pred_binary = post_process_mangrove_prediction(pred_binary, mode=postproc_mode)
            # ‚≠ê‚≠ê‚≠ê FIN DEL POST-PROCESAMIENTO ‚≠ê‚≠ê‚≠ê
            
            # Guardar predicci√≥n
            tile_name = tile_path.stem
            pred_filename = f"pred_{tile_name}.tif"
            pred_path = output_dir / pred_filename
            
            save_prediction_geotiff(pred_binary, profile, transform, str(pred_path))
            
            pred_files.append(str(pred_path))
            
        except Exception as e:
            print(f"\n‚ö†Ô∏è Error procesando {tile_path.name}: {str(e)}")
            continue
    
    print(f"\n‚úÖ {len(pred_files)} teselas procesadas exitosamente")
    return pred_files


def create_mosaic(pred_files, output_mosaic_path, method='first'):
    """Crea un mosaico a partir de las predicciones individuales"""
    print(f"\nüß© Creando mosaico de {len(pred_files)} teselas...")
    
    src_files_to_mosaic = []
    for fp in pred_files:
        src = rasterio.open(fp)
        src_files_to_mosaic.append(src)
    
    mosaic, out_trans = merge(src_files_to_mosaic, method=method)
    
    for src in src_files_to_mosaic:
        src.close()
    
    with rasterio.open(pred_files[0]) as src:
        out_meta = src.meta.copy()
    
    out_meta.update({
        "driver": "GTiff",
        "height": mosaic.shape[1],
        "width": mosaic.shape[2],
        "transform": out_trans,
        "compress": "lzw"
    })
    
    with rasterio.open(output_mosaic_path, "w", **out_meta) as dest:
        dest.write(mosaic)
        dest.write_colormap(1, {
            0: (139, 69, 19),
            1: (34, 139, 34),
            255: (0, 0, 0)
        })
    
    print(f"‚úÖ Mosaico creado: {output_mosaic_path}")
    print(f"   Dimensiones: {mosaic.shape[2]} x {mosaic.shape[1]} p√≠xeles")
    
    mosaic_data = mosaic[0]
    total_pixels = mosaic_data.size
    manglar_pixels = np.sum(mosaic_data == 1)
    no_manglar_pixels = np.sum(mosaic_data == 0)
    nodata_pixels = np.sum(mosaic_data == 255)
    
    manglar_pct = 100 * manglar_pixels / (total_pixels - nodata_pixels) if (total_pixels - nodata_pixels) > 0 else 0
    
    print(f"\nüìä Estad√≠sticas del Mosaico:")
    print(f"   Total p√≠xeles:        {total_pixels:,}")
    print(f"   P√≠xeles Manglar:      {manglar_pixels:,} ({manglar_pct:.2f}%)")
    print(f"   P√≠xeles No-Manglar:   {no_manglar_pixels:,}")
    print(f"   P√≠xeles NoData:       {nodata_pixels:,}")
    
    return output_mosaic_path


def apply_study_area_mask(mosaic_path, shapefile_path, output_path=None):
    """
    Aplica m√°scara del √°rea de estudio al mosaico.

    Args:
        mosaic_path: Ruta al mosaico TIF
        shapefile_path: Ruta al shapefile del √°rea de estudio
        output_path: Ruta de salida (si None, sobrescribe el original)

    Returns:
        Ruta al mosaico enmascarado
    """
    print(f"\nüó∫Ô∏è  Aplicando m√°scara del √°rea de estudio...")
    print(f"   Shapefile: {Path(shapefile_path).name}")

    # Leer shapefile
    gdf = gpd.read_file(shapefile_path)
    print(f"   CRS shapefile: {gdf.crs}")
    print(f"   Geometr√≠as: {len(gdf)}")

    # Abrir mosaico
    with rasterio.open(mosaic_path) as src:
        print(f"   CRS mosaico: {src.crs}")

        # Reproyectar shapefile si es necesario
        if gdf.crs != src.crs:
            print(f"   ‚ö†Ô∏è  Reproyectando shapefile de {gdf.crs} a {src.crs}")
            gdf = gdf.to_crs(src.crs)

        # Aplicar m√°scara
        # crop=False mantiene la extensi√≥n original
        # filled=True rellena √°reas fuera con nodata
        out_image, out_transform = rasterio_mask(
            src,
            gdf.geometry,
            crop=False,
            filled=True,
            nodata=255  # NoData para √°reas fuera
        )

        # Copiar metadatos
        out_meta = src.meta.copy()
        out_meta.update({
            "driver": "GTiff",
            "height": out_image.shape[1],
            "width": out_image.shape[2],
            "transform": out_transform,
            "nodata": 255,
            "compress": "lzw"
        })

    # Determinar ruta de salida
    if output_path is None:
        output_path = mosaic_path  # Sobrescribir original

    # Guardar mosaico enmascarado
    with rasterio.open(output_path, "w", **out_meta) as dest:
        dest.write(out_image)
        dest.write_colormap(1, {
            0: (139, 69, 19),    # No-Manglar (marr√≥n)
            1: (34, 139, 34),     # Manglar (verde)
            255: (0, 0, 0)        # NoData (negro/transparente)
        })

    # Estad√≠sticas
    mosaic_data = out_image[0]
    total_pixels = mosaic_data.size
    manglar_pixels = np.sum(mosaic_data == 1)
    no_manglar_pixels = np.sum(mosaic_data == 0)
    nodata_pixels = np.sum(mosaic_data == 255)

    valid_pixels = total_pixels - nodata_pixels
    manglar_pct = 100 * manglar_pixels / valid_pixels if valid_pixels > 0 else 0

    print(f"\n   ‚úÖ M√°scara aplicada: {Path(output_path).name}")
    print(f"   üìä Estad√≠sticas del √°rea de estudio:")
    print(f"      P√≠xeles dentro:       {valid_pixels:,} ({100*valid_pixels/total_pixels:.1f}%)")
    print(f"      P√≠xeles fuera (NoData): {nodata_pixels:,} ({100*nodata_pixels/total_pixels:.1f}%)")
    print(f"      Manglar:              {manglar_pixels:,} ({manglar_pct:.2f}% del √°rea)")
    print(f"      No-Manglar:           {no_manglar_pixels:,}")

    return output_path


def visualize_mosaic(mosaic_path, output_viz_path, year, figsize=(16, 12), dpi=300,
                     shapefile_path=None):
    """
    Visualiza el mosaico final con m√∫ltiples m√©todos de visualizaci√≥n

    Genera 3 visualizaciones:
    1. Mosaico est√°ndar (colores originales)
    2. Mosaico con verde ne√≥n (alta visibilidad)
    3. Mapa de calor de densidad

    Args:
        mosaic_path: Ruta al mosaico GeoTIFF
        output_viz_path: Ruta de salida para visualizaci√≥n est√°ndar
        year: A√±o de an√°lisis
        figsize: Tama√±o de la figura (ancho, alto)
        dpi: Resoluci√≥n de salida
        shapefile_path: Ruta al shapefile del √°rea de estudio (opcional)
    """
    from matplotlib.colors import BoundaryNorm

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # FUNCIONES AUXILIARES PARA ELEMENTOS CARTOGR√ÅFICOS
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    def add_scale_bar(ax, left, right, bottom, top):
        """A√±ade barra de escala cartogr√°fica al gr√°fico."""
        extent_width = right - left
        scale_length_m = 10000  # 10 km por defecto

        if extent_width < 30000:
            scale_length_m = 5000  # 5 km

        center_x = (left + right) / 2
        bar_x = center_x - scale_length_m / 2
        bar_y = top - 2500  # 2.5 km del borde superior

        # Fondo negro
        ax.plot([bar_x, bar_x + scale_length_m], [bar_y, bar_y],
               color='black', linewidth=6, solid_capstyle='butt', zorder=12)

        # Barra blanca
        ax.plot([bar_x, bar_x + scale_length_m], [bar_y, bar_y],
               color='white', linewidth=4, solid_capstyle='butt', zorder=13)

        # Segmentos
        segment_length = scale_length_m / 4
        for i in range(5):
            x_pos = bar_x + i * segment_length
            ax.plot([x_pos, x_pos], [bar_y - 150, bar_y + 150],
                   color='white', linewidth=2, zorder=13)

        # Etiquetas
        label_km = scale_length_m / 1000
        ax.text(bar_x, bar_y - 600, '0', ha='center', va='top',
               color='white', fontsize=8, weight='bold',
               bbox=dict(boxstyle='round,pad=0.3', facecolor='black', alpha=0.7),
               zorder=14)
        ax.text(bar_x + scale_length_m, bar_y - 600, f'{label_km:.0f} km',
               ha='center', va='top',
               color='white', fontsize=8, weight='bold',
               bbox=dict(boxstyle='round,pad=0.3', facecolor='black', alpha=0.7),
               zorder=14)

    def add_north_arrow(ax):
        """A√±ade flecha de norte discreta al gr√°fico."""
        arrow_x = 0.05
        arrow_y = 0.70

        # Fondo negro
        ax.annotate('', xy=(arrow_x, arrow_y), xycoords='axes fraction',
                   xytext=(arrow_x, arrow_y - 0.06),
                   arrowprops=dict(arrowstyle='->', lw=4, color='black',
                                 mutation_scale=20),
                   zorder=13)

        # Flecha blanca
        ax.annotate('', xy=(arrow_x, arrow_y), xycoords='axes fraction',
                   xytext=(arrow_x, arrow_y - 0.06),
                   arrowprops=dict(arrowstyle='->', lw=2.5, color='white',
                                 mutation_scale=20),
                   zorder=14)

        # Etiqueta "N"
        ax.text(arrow_x, arrow_y + 0.015, 'N',
               transform=ax.transAxes,
               ha='center', va='bottom',
               fontsize=14, weight='bold', color='white',
               bbox=dict(boxstyle='circle,pad=0.3', facecolor='black',
                        alpha=0.75, edgecolor='white', linewidth=1.5),
               zorder=14)

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # INICIO DE LA VISUALIZACI√ìN
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    print(f"\nüé® Generando visualizaciones del mosaico...")

    with rasterio.open(mosaic_path) as src:
        mosaic = src.read(1)
        bounds = src.bounds
        extent = [bounds.left, bounds.right, bounds.bottom, bounds.top]
        crs = src.crs

    output_dir = Path(output_viz_path).parent

    # Cargar shapefile si est√° disponible
    gdf = None
    if shapefile_path is not None:
        shapefile_path = Path(shapefile_path)
        if shapefile_path.exists():
            print(f"   Cargando shapefile: {shapefile_path.name}")
            gdf = gpd.read_file(shapefile_path)
            # Reproyectar si es necesario
            if gdf.crs != crs:
                print(f"   Reproyectando shapefile de {gdf.crs} a {crs}")
                gdf = gdf.to_crs(crs)
    
    # Estad√≠sticas para todas las visualizaciones
    manglar_pixels = np.sum(mosaic == 1)
    no_manglar_pixels = np.sum(mosaic == 0)
    nodata_pixels = np.sum(mosaic == 255)
    total_pixels = mosaic.size
    manglar_pct = (manglar_pixels / (total_pixels - nodata_pixels)) * 100 if (total_pixels - nodata_pixels) > 0 else 0
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # VISUALIZACI√ìN 1: VERDE NE√ìN (ALTA VISIBILIDAD)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    print(f"   Generando mosaico con verde ne√≥n...")

    # Reasignar valores para mapeo correcto y transparencia
    mosaic_vis = mosaic.copy().astype(np.float32)
    mosaic_vis[mosaic == 255] = np.nan  # √Åreas sin datos como NaN para transparencia

    # Crear figura con aspect ratio del mosaico
    height, width = mosaic.shape
    aspect_ratio = width / height
    fig_width = 18
    fig_height = fig_width / aspect_ratio
    fig, ax = plt.subplots(figsize=(fig_width, fig_height))

    # Fondo celeste claro para representar agua (COMO EN FALSO COLOR)
    ax.set_facecolor('#87CEEB')

    # Colores: Celeste claro (no manglar), Verde NE√ìN (manglar)
    # Usamos transparencia para NoData en lugar de color gris
    colors_neon = ['#87CEEB', '#39FF14']  # Agua=Celeste, Manglar=Verde ne√≥n
    cmap_neon = ListedColormap(colors_neon)
    norm_neon = BoundaryNorm(boundaries=[-0.5, 0.5, 1.5], ncolors=2)

    im = ax.imshow(mosaic_vis, cmap=cmap_neon, norm=norm_neon, extent=extent,
                   interpolation='none', aspect='equal')

    # Colorbar con solo 2 categor√≠as (sin NoData)
    #cbar = plt.colorbar(im, ax=ax, fraction=0.03, pad=0.04, ticks=[0, 1])
    #cbar.ax.set_yticklabels(['No Manglar (Agua/Tierra)', 'MANGLAR'], fontsize=11)
    #cbar.ax.tick_params(labelsize=10)

    # Superponer contorno del shapefile (COMO EN FALSO COLOR)
    if gdf is not None:
        # Contorno doble (negro + amarillo dorado) para mejor visibilidad
        gdf.boundary.plot(ax=ax, color='black', linewidth=2.5,
                         linestyle='-', alpha=0.9, zorder=10)
        gdf.boundary.plot(ax=ax, color='#FFD700', linewidth=1.5,
                         linestyle='-', alpha=1.0, zorder=11,
                         label='L√≠mite del √°rea de estudio')

        # Leyenda
        ax.legend(loc='upper right', fontsize=16, framealpha=0.9,
                 fancybox=True, shadow=True, edgecolor='black')

    # L√≠mites del gr√°fico
    ax.set_xlim(extent[0], extent[1])
    ax.set_ylim(extent[2], extent[3])

    # T√≠tulos y etiquetas (ESTILO FALSO COLOR)
    ax.set_xlabel('Longitud (m)', fontsize=12)
    ax.set_ylabel('Latitud (m)', fontsize=12)
    ax.set_title(f'Segmentaci√≥n de Manglares - A√±o {year}\n' +
                 f'Verde Ne√≥n = Manglar ({manglar_pixels:,} p√≠xeles, {manglar_pct:.2f}%)',
                 fontsize=22, fontweight='bold', pad=15)

    # Grid sutil (COMO EN FALSO COLOR)
    ax.grid(True, alpha=0.15, linestyle=':', linewidth=0.3, color='white')

    # Caja de informaci√≥n mejorada (ESTILO FALSO COLOR)
    info_lines = [
        "Estad√≠sticas:",
        f"  Manglar: {manglar_pixels:,} px ({manglar_pct:.2f}%)",
        f"  No-Manglar: {no_manglar_pixels:,} px",
        "",
        "√Årea de Estudio:",
        "  Archipi√©lago de Jambel√≠",
        "",
        "Resoluci√≥n:",
        "  10 m/p√≠xel"
    ]
    info_text = "\n".join(info_lines)

    ax.text(0.02, 0.98, info_text,
           transform=ax.transAxes,
           fontsize=18,
           verticalalignment='top',
           horizontalalignment='left',
           family='monospace',
           bbox=dict(boxstyle='round,pad=0.6', facecolor='black', alpha=0.75,
                    edgecolor='#FFD700', linewidth=1.5),
           color='white',
           zorder=15)

    # A√±adir elementos cartogr√°ficos (COMO EN FALSO COLOR)
    add_scale_bar(ax, extent[0], extent[1], extent[2], extent[3])
    add_north_arrow(ax)

    plt.tight_layout()
    plt.subplots_adjust(left=0.1, right=0.95, top=0.95, bottom=0.1)

    neon_path = output_dir / f"mosaico_VERDE_NEON_{year}.png"
    plt.savefig(neon_path, dpi=300, bbox_inches='tight', facecolor='white', pad_inches=0.2)
    plt.close()

    print(f"   ‚úÖ Verde ne√≥n guardado: {neon_path.name}")
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # VISUALIZACI√ìN 2: MAPA DE CALOR DE DENSIDAD
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    print(f"   Generando mapa de calor de densidad...")

    # Calcular densidad en bloques
    block_size = 50
    h, w = mosaic.shape
    h_blocks = h // block_size
    w_blocks = w // block_size

    density_map = np.zeros((h_blocks, w_blocks))

    for i in range(h_blocks):
        for j in range(w_blocks):
            block = mosaic[i*block_size:(i+1)*block_size, j*block_size:(j+1)*block_size]
            density_map[i, j] = (block == 1).sum() / block.size * 100

    # Crear figura con aspect ratio del mosaico
    aspect_ratio = w / h
    fig_width = 18
    fig_height = fig_width / aspect_ratio
    fig, ax = plt.subplots(figsize=(fig_width, fig_height))

    # Fondo celeste claro para representar agua (COMO EN FALSO COLOR)
    ax.set_facecolor('#87CEEB')

    im = ax.imshow(density_map, cmap='YlGn', extent=extent,
                   interpolation='bilinear', aspect='equal',
                   vmin=0, vmax=max(density_map.max(), 1))

    cbar = plt.colorbar(im, ax=ax, fraction=0.03, pad=0.04)
    cbar.set_label('Densidad de Manglar (%)', rotation=270, labelpad=25,
                   fontsize=12, weight='bold')
    cbar.ax.tick_params(labelsize=10)

    # Superponer contorno del shapefile (COMO EN FALSO COLOR)
    if gdf is not None:
        # Contorno doble (negro + amarillo dorado) para mejor visibilidad
        gdf.boundary.plot(ax=ax, color='black', linewidth=2.5,
                         linestyle='-', alpha=0.9, zorder=10)
        gdf.boundary.plot(ax=ax, color='#FFD700', linewidth=1.5,
                         linestyle='-', alpha=1.0, zorder=11,
                         label='L√≠mite del √°rea de estudio')

        # Leyenda
        ax.legend(loc='upper right', fontsize=9, framealpha=0.9,
                 fancybox=True, shadow=True, edgecolor='black')

    # L√≠mites del gr√°fico
    ax.set_xlim(extent[0], extent[1])
    ax.set_ylim(extent[2], extent[3])

    # T√≠tulos y etiquetas (ESTILO FALSO COLOR)
    ax.set_xlabel('Longitud (m)', fontsize=12)
    ax.set_ylabel('Latitud (m)', fontsize=12)
    ax.set_title(f'Mapa de Calor - Densidad de Manglar (A√±o {year})\n' +
                 f'Bloques de {block_size}√ó{block_size} p√≠xeles | Amarillo-Verde = Mayor densidad',
                 fontsize=18, fontweight='bold', pad=15)

    # Grid sutil (COMO EN FALSO COLOR)
    ax.grid(True, alpha=0.15, linestyle=':', linewidth=0.3, color='white')

    # Caja de informaci√≥n mejorada (ESTILO FALSO COLOR)
    max_density = density_map.max()
    mean_density = density_map[density_map > 0].mean() if (density_map > 0).any() else 0

    info_lines = [
        "Estad√≠sticas de Densidad:",
        f"  M√°xima: {max_density:.1f}%",
        f"  Promedio: {mean_density:.1f}%",
        f"  Bloque: {block_size}√ó{block_size} px",
        "",
        "√Årea de Estudio:",
        "  Archipi√©lago de Jambel√≠",
        "",
        "Resoluci√≥n:",
        "  10 m/p√≠xel"
    ]
    info_text = "\n".join(info_lines)

    ax.text(0.98, 0.02, info_text,
           transform=ax.transAxes,
           fontsize=9,
           verticalalignment='bottom',
           horizontalalignment='right',
           family='monospace',
           bbox=dict(boxstyle='round,pad=0.6', facecolor='black', alpha=0.75,
                    edgecolor='#FFD700', linewidth=1.5),
           color='white',
           zorder=15)

    # A√±adir elementos cartogr√°ficos (COMO EN FALSO COLOR)
    add_scale_bar(ax, extent[0], extent[1], extent[2], extent[3])
    add_north_arrow(ax)

    plt.tight_layout()
    plt.subplots_adjust(left=0.1, right=0.95, top=0.95, bottom=0.1)

    heatmap_path = output_dir / f"mosaico_HEATMAP_{year}.png"
    plt.savefig(heatmap_path, dpi=300, bbox_inches='tight', facecolor='white', pad_inches=0.2)
    plt.close()

    print(f"   ‚úÖ Mapa de calor guardado: {heatmap_path.name}")
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # VISUALIZACI√ìN 3: EST√ÅNDAR (COMPATIBILIDAD)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    print(f"   Generando mosaico est√°ndar...")
    
    fig, ax = plt.subplots(figsize=figsize)
    
    colors_std = ['#8B4513', '#228B22', '#000000']
    cmap_std = ListedColormap(colors_std)
    
    im = ax.imshow(mosaic, cmap=cmap_std, extent=extent, interpolation='nearest')
    
    cbar = plt.colorbar(im, ax=ax, fraction=0.03, pad=0.04)
    cbar.set_ticks([0, 1, 255])
    cbar.set_ticklabels(['No Manglar', 'Manglar', 'NoData'])
    
    ax.set_xlabel('Longitud', fontsize=12, fontweight='bold')
    ax.set_ylabel('Latitud', fontsize=12, fontweight='bold')
    ax.set_title(f'Mosaico de Predicci√≥n - Segmentaci√≥n de Manglares (A√±o {year})', 
                 fontsize=14, fontweight='bold', pad=20)
    
    ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)
    
    plt.tight_layout()
    plt.savefig(output_viz_path, dpi=dpi, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"   ‚úÖ Mosaico est√°ndar guardado: {Path(output_viz_path).name}")
    
    print(f"\n‚úÖ 3 visualizaciones generadas exitosamente:")
    print(f"   1. {neon_path.name} (verde ne√≥n, alta visibilidad)")
    print(f"   2. {heatmap_path.name} (mapa de calor)")
    print(f"   3. {Path(output_viz_path).name} (est√°ndar)")


def generate_tile_visualizations(images_dir, masks_dir, predictions_dir, output_viz_dir,
                                  year, max_tiles=50, selection_mode='best'):
    """
    Genera visualizaciones comparativas individuales: RGB | Ground Truth | Predicci√≥n

    Args:
        images_dir: Directorio con im√°genes originales
        masks_dir: Directorio con m√°scaras ground truth
        predictions_dir: Directorio con predicciones
        output_viz_dir: Directorio de salida para visualizaciones
        year: A√±o de an√°lisis
        max_tiles: N√∫mero m√°ximo de visualizaciones a generar
        selection_mode: Modo de selecci√≥n ('best', 'worst', 'random', 'all')

    Returns:
        N√∫mero de visualizaciones generadas
    """

    print(f"\nüé® Generando visualizaciones de teselas individuales...")
    print(f"   Modo de selecci√≥n: {selection_mode}")
    print(f"   M√°ximo de teselas: {max_tiles if selection_mode != 'all' else 'todas'}")

    # Buscar archivos de predicci√≥n
    pred_files = sorted(predictions_dir.glob("pred_*.tif"))

    if len(pred_files) == 0:
        print(f"‚ö†Ô∏è No se encontraron predicciones en {predictions_dir}")
        return 0

    # Calcular IoU para cada tesela y seleccionar cu√°les visualizar
    tiles_data = []

    for pred_path in tqdm(pred_files, desc="Calculando IoU de teselas"):
        # Extraer nombre de tesela
        pred_name = pred_path.stem
        tile_name = pred_name.replace('pred_', '')

        # Buscar imagen y m√°scara correspondiente
        image_path = images_dir / f"{tile_name}.tif"
        mask_path = masks_dir / f"{tile_name.replace('_r', '_mask_r')}.tif"

        if not image_path.exists():
            continue

        if not mask_path.exists():
            # Intentar patrones alternativos
            alt_patterns = [
                masks_dir / f"{tile_name}_mask.tif",
                masks_dir / f"mask_{tile_name}.tif",
            ]
            for alt_path in alt_patterns:
                if alt_path.exists():
                    mask_path = alt_path
                    break
            else:
                continue  # No se encontr√≥ m√°scara

        try:
            # Leer predicci√≥n y m√°scara
            with rasterio.open(pred_path) as src:
                pred = src.read(1)

            with rasterio.open(mask_path) as src:
                mask = src.read(1)

            # Calcular IoU
            if pred.shape != mask.shape:
                continue

            # Filtrar NaN y calcular IoU solo si hay manglar
            valid_pixels = ~np.isnan(mask)
            mask_clean = mask[valid_pixels]
            pred_clean = pred[valid_pixels]

            # Saltar m√°scaras vac√≠as
            if len(np.unique(mask_clean)) == 1 and np.unique(mask_clean)[0] == 0:
                continue

            TP = np.sum((pred_clean == 1) & (mask_clean == 1))
            FP = np.sum((pred_clean == 1) & (mask_clean == 0))
            FN = np.sum((pred_clean == 0) & (mask_clean == 1))

            tile_iou = TP / (TP + FP + FN) if (TP + FP + FN) > 0 else 0.0

            tiles_data.append({
                'tile_name': tile_name,
                'image_path': image_path,
                'mask_path': mask_path,
                'pred_path': pred_path,
                'iou': tile_iou,
                'manglar_pct_real': (mask_clean == 1).sum() / len(mask_clean) * 100,
                'manglar_pct_pred': (pred_clean == 1).sum() / len(pred_clean) * 100,
            })

        except Exception as e:
            continue

    if len(tiles_data) == 0:
        print(f"‚ö†Ô∏è No se pudieron calcular IoU para ninguna tesela")
        return 0

    # Seleccionar teselas seg√∫n el modo
    if selection_mode == 'best':
        tiles_data.sort(key=lambda x: x['iou'], reverse=True)
        selected_tiles = tiles_data[:max_tiles]
        print(f"   üìä Seleccionadas {len(selected_tiles)} mejores teselas (IoU: {selected_tiles[0]['iou']:.4f} - {selected_tiles[-1]['iou']:.4f})")
    elif selection_mode == 'worst':
        tiles_data.sort(key=lambda x: x['iou'])
        selected_tiles = tiles_data[:max_tiles]
        print(f"   üìä Seleccionadas {len(selected_tiles)} peores teselas (IoU: {selected_tiles[0]['iou']:.4f} - {selected_tiles[-1]['iou']:.4f})")
    elif selection_mode == 'random':
        import random
        selected_tiles = random.sample(tiles_data, min(max_tiles, len(tiles_data)))
        print(f"   üìä Seleccionadas {len(selected_tiles)} teselas aleatorias")
    else:  # 'all'
        selected_tiles = tiles_data
        print(f"   üìä Generando visualizaciones para todas las {len(selected_tiles)} teselas")

    # Generar visualizaciones
    colors = ['#8B4513', '#228B22']  # Marr√≥n para no-manglar, verde para manglar
    cmap = ListedColormap(colors)

    viz_count = 0
    for idx, tile_data in enumerate(tqdm(selected_tiles, desc="Generando visualizaciones")):
        try:
            # Leer imagen RGB (bandas 2, 3, 4 = RGB)
            with rasterio.open(tile_data['image_path']) as src:
                image = src.read()

            # Crear composici√≥n RGB (asumiendo orden: B2, B3, B4, B8, B11, B12)
            if image.shape[0] >= 3:
                rgb = np.stack([image[2], image[1], image[0]], axis=-1)  # B4, B3, B2

                # Filtrar NaN antes de normalizar
                valid_mask = ~np.isnan(rgb).any(axis=2)
                rgb_clean = rgb[valid_mask]

                if len(rgb_clean) == 0:
                    # Imagen completamente NaN
                    rgb_vis = np.full((rgb.shape[0], rgb.shape[1], 3), 128, dtype=np.uint8)
                else:
                    # Normalizaci√≥n robusta con estrategia adaptativa
                    p1, p99 = np.percentile(rgb_clean, (1, 99))
                    p_range = p99 - p1

                    if p_range < 0.01:
                        # Rango muy peque√±o: usar min-max directo
                        rgb_min = rgb_clean.min()
                        rgb_max = rgb_clean.max()
                        if rgb_max - rgb_min > 0:
                            rgb_normalized = (rgb - rgb_min) / (rgb_max - rgb_min)
                        else:
                            rgb_normalized = np.full_like(rgb, 0.5)
                    else:
                        # Normalizaci√≥n percentil est√°ndar
                        rgb_normalized = np.clip((rgb - p1) / p_range, 0, 1)

                    # Detecci√≥n de imagen oscura (agua, sombras)
                    mean_intensity = rgb_clean.mean()
                    is_dark_image = mean_intensity < 0.08  # Umbral emp√≠rico

                    if is_dark_image:
                        # Aplicar gamma correction para realzar detalles en zonas oscuras
                        gamma = 0.5  # Gamma < 1 aclara la imagen
                        rgb_normalized = np.power(rgb_normalized, gamma)

                    # Convertir a uint8
                    rgb_vis = (rgb_normalized * 255).astype(np.uint8)

                    # Restaurar NaN como negro
                    rgb_vis[~valid_mask] = 0
            else:
                # Si no hay suficientes bandas, usar imagen en escala de grises
                rgb_vis = np.stack([image[0]] * 3, axis=-1)

            # Leer m√°scara y predicci√≥n
            with rasterio.open(tile_data['mask_path']) as src:
                mask = src.read(1)

            with rasterio.open(tile_data['pred_path']) as src:
                pred = src.read(1)

            # Crear visualizaci√≥n
            fig, axes = plt.subplots(1, 3, figsize=(15, 5))

            # Panel 1: RGB
            axes[0].imshow(rgb_vis)

            # T√≠tulo adaptativo seg√∫n tipo de imagen
            if len(rgb_clean) > 0:
                mean_intensity = rgb_clean.mean()
                is_dark_image = mean_intensity < 0.08

                if is_dark_image:
                    rgb_title = f'Imagen Satelital (RGB)\n‚ö†Ô∏è Zona muy oscura (agua/sombra)\nŒ≥-correcci√≥n aplicada'
                    axes[0].set_title(rgb_title, fontsize=11, fontweight='bold', color='#FF6B35')
                else:
                    axes[0].set_title('Imagen Satelital (RGB)', fontsize=12, fontweight='bold')
            else:
                axes[0].set_title('Imagen Satelital (RGB)\n‚ö†Ô∏è Sin datos', fontsize=11, fontweight='bold', color='red')

            axes[0].axis('off')

            # Panel 2: Ground Truth
            axes[1].imshow(mask, cmap=cmap, vmin=0, vmax=1)
            axes[1].set_title(f'Ground Truth\n{tile_data["manglar_pct_real"]:.1f}% manglar',
                            fontsize=12, fontweight='bold')
            axes[1].axis('off')

            # Panel 3: Predicci√≥n
            axes[2].imshow(pred, cmap=cmap, vmin=0, vmax=1)
            axes[2].set_title(f'Predicci√≥n\nIoU: {tile_data["iou"]:.4f} | {tile_data["manglar_pct_pred"]:.1f}% manglar',
                            fontsize=12, fontweight='bold')
            axes[2].axis('off')

            fig.suptitle(f'Tesela: {tile_data["tile_name"]} | A√±o: {year}',
                        fontsize=14, fontweight='bold', y=1.02)

            plt.tight_layout()

            # Guardar con formato numerado
            viz_filename = f"viz_{idx:04d}_{tile_data['tile_name']}.png"
            viz_path = output_viz_dir / viz_filename
            plt.savefig(viz_path, dpi=200, bbox_inches='tight', facecolor='white')
            plt.close()

            viz_count += 1

        except Exception as e:
            print(f"\n‚ö†Ô∏è Error generando visualizaci√≥n para {tile_data['tile_name']}: {str(e)}")
            continue

    print(f"\n‚úÖ {viz_count} visualizaciones generadas exitosamente")
    print(f"   üìÅ Guardadas en: {output_viz_dir}/")

    return viz_count


def calculate_area_statistics(mosaic_path, output_report_path, year):
    """
    Calcula estad√≠sticas de √°rea del mosaico
    
    ‚úÖ MEJORADO: Detecci√≥n autom√°tica de CRS y reproyecci√≥n condicional
    
    - Detecta si la imagen est√° en coordenadas geogr√°ficas o proyectadas
    - Reproyecta SOLO si es necesario (coordenadas geogr√°ficas)
    - Preserva metadatos originales cuando ya est√° en sistema proyectado
    
    FLUJO DE PROCESAMIENTO:
    1. Lee mosaico y metadatos espaciales
    2. Detecta tipo de CRS (geogr√°fico vs proyectado)
    3. Si geogr√°fico ‚Üí reproyecta a UTM
    4. Si proyectado ‚Üí usa metadatos originales sin cambios
    5. Calcula √°reas con resoluci√≥n correcta
    """
    print(f"\nüìê Calculando estad√≠sticas de √°rea...")
    
    with rasterio.open(mosaic_path) as src:
        mosaic = src.read(1)
        original_transform = src.transform
        original_crs = src.crs
        bounds = src.bounds
        
        print(f"\n{'='*70}")
        print(f"üìç AN√ÅLISIS DE SISTEMA DE COORDENADAS")
        print(f"{'='*70}")
        print(f"CRS original: {original_crs}")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # üîç DETECCI√ìN ROBUSTA DE CRS GEOGR√ÅFICO vs PROYECTADO
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        
        is_geographic, detection_method, crs_info = is_crs_geographic(original_crs)
        
        print(f"\nüîç Resultados de la detecci√≥n:")
        print(f"   Tipo de CRS: {'üåç GEOGR√ÅFICO (grados)' if is_geographic else 'üìê PROYECTADO (metros)'}")
        print(f"   M√©todo de detecci√≥n: {detection_method}")
        
        # Mostrar informaci√≥n adicional del CRS
        if 'units' in crs_info:
            print(f"   Unidades detectadas: {crs_info['units']}")
        if 'zone' in crs_info:
            print(f"   Zona UTM: {crs_info['zone']}")
        if 'epsg' in crs_info:
            print(f"   C√≥digo EPSG: {crs_info['epsg']}")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # üîÑ REPROYECCI√ìN CONDICIONAL
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        print(f"\n{'='*70}")
        print(f"üìê DECISI√ìN DE REPROYECCI√ìN")
        print(f"{'='*70}")

        if is_geographic:
            print(f"\n‚ö†Ô∏è  Imagen en coordenadas GEOGR√ÅFICAS detectada")
            print(f"   Raz√≥n: Las coordenadas est√°n en grados (latitud/longitud)")
            print(f"   Acci√≥n: REPROYECTAR a UTM para c√°lculo preciso de √°reas")
            print(f"\nüîÑ Iniciando reproyecci√≥n a UTM zona 17S (EPSG:32717)...")
            
            # Definir CRS destino (UTM 17S para Ecuador)
            dst_crs = CRS.from_epsg(32717)
            
            print(f"   Origen: {original_crs}")
            print(f"   Destino: {dst_crs}")
            print(f"   M√©todo de remuestreo: Nearest Neighbor (preserva valores binarios)")
            
            # Calcular transformaci√≥n
            dst_transform, width, height = calculate_default_transform(
                original_crs, dst_crs, src.width, src.height, *bounds
            )
            
            print(f"   Dimensiones originales: {src.width} √ó {src.height} p√≠xeles")
            print(f"   Dimensiones destino: {width} √ó {height} p√≠xeles")
            
            # Crear array de destino
            mosaic_utm = np.empty((height, width), dtype=mosaic.dtype)
            
            # Reproyectar
            reproject(
                source=mosaic,
                destination=mosaic_utm,
                src_transform=original_transform,
                src_crs=original_crs,
                dst_transform=dst_transform,
                dst_crs=dst_crs,
                resampling=Resampling.nearest
            )
            
            # Usar datos reproyectados
            mosaic = mosaic_utm
            transform = dst_transform
            crs = dst_crs
            
            print(f"\n‚úÖ Reproyecci√≥n completada exitosamente")
            print(f"   CRS final: {crs}")
            print(f"   Dimensiones finales: {mosaic.shape[1]} √ó {mosaic.shape[0]} p√≠xeles")
            
        else:
            # Ya est√° en coordenadas proyectadas - NO reproyectar
            print(f"\n‚úÖ Imagen en coordenadas PROYECTADAS detectada")
            print(f"   Raz√≥n: El CRS ya est√° en un sistema proyectado (unidades m√©tricas)")
            print(f"   Acci√≥n: OMITIR reproyecci√≥n (no es necesaria)")
            print(f"\nüéØ Preservando metadatos originales:")
            print(f"   ‚úì CRS original: {original_crs}")
            print(f"   ‚úì Transform original preservado")
            print(f"   ‚úì Resoluci√≥n espacial intacta")
            print(f"   ‚úì No hay p√©rdida de precisi√≥n por reproyecci√≥n")
            
            transform = original_transform
            crs = original_crs
            
            # Mostrar informaci√≥n de la resoluci√≥n original
            orig_pixel_width = abs(original_transform[0])
            orig_pixel_height = abs(original_transform[4])
            print(f"   ‚úì Resoluci√≥n: {orig_pixel_width:.2f} √ó {orig_pixel_height:.2f} metros")
        
        # Calcular tama√±o de p√≠xel en metros
        pixel_width = abs(transform[0])
        pixel_height = abs(transform[4])
        pixel_area_m2 = pixel_width * pixel_height
        pixel_area_ha = pixel_area_m2 / 10000
        
        print(f"   üìè Resoluci√≥n: {pixel_width:.2f} x {pixel_height:.2f} metros")
        print(f"   üìê √Årea por p√≠xel: {pixel_area_m2:.2f} m¬≤ ({pixel_area_ha:.6f} ha)")
    
    total_pixels = mosaic.size
    manglar_pixels = np.sum(mosaic == 1)
    no_manglar_pixels = np.sum(mosaic == 0)
    nodata_pixels = np.sum(mosaic == 255)
    valid_pixels = total_pixels - nodata_pixels
    
    area_manglar_ha = manglar_pixels * pixel_area_ha
    area_no_manglar_ha = no_manglar_pixels * pixel_area_ha
    area_total_ha = valid_pixels * pixel_area_ha
    
    manglar_pct = 100 * manglar_pixels / valid_pixels if valid_pixels > 0 else 0
    
    with open(output_report_path, 'w', encoding='utf-8') as f:
        f.write("="*70 + "\n")
        f.write(f"REPORTE DE √ÅREA - MOSAICO DE PREDICCI√ìN (A√ëO {year})\n")
        f.write("="*70 + "\n\n")
        
        f.write("INFORMACI√ìN ESPACIAL:\n")
        f.write("-"*70 + "\n")
        f.write(f"A√±o de an√°lisis:        {year}\n")
        f.write(f"CRS:                    {crs}\n")
        f.write(f"Resoluci√≥n espacial:    {pixel_width:.2f} x {pixel_height:.2f} metros\n")
        f.write(f"√Årea por p√≠xel:         {pixel_area_m2:.2f} m¬≤ ({pixel_area_ha:.6f} ha)\n")
        f.write("-"*70 + "\n\n")
        
        f.write("CONTEO DE P√çXELES:\n")
        f.write("-"*70 + "\n")
        f.write(f"Total de p√≠xeles:       {total_pixels:,}\n")
        f.write(f"P√≠xeles v√°lidos:        {valid_pixels:,}\n")
        f.write(f"P√≠xeles Manglar:        {manglar_pixels:,}\n")
        f.write(f"P√≠xeles No-Manglar:     {no_manglar_pixels:,}\n")
        f.write(f"P√≠xeles NoData:         {nodata_pixels:,}\n")
        f.write("-"*70 + "\n\n")
        
        f.write("√ÅREA (HECT√ÅREAS):\n")
        f.write("-"*70 + "\n")
        f.write(f"√Årea total (v√°lida):    {area_total_ha:,.2f} ha\n")
        f.write(f"√Årea de Manglar:        {area_manglar_ha:,.2f} ha ({manglar_pct:.2f}%)\n")
        f.write(f"√Årea de No-Manglar:     {area_no_manglar_ha:,.2f} ha ({100-manglar_pct:.2f}%)\n")
        f.write("-"*70 + "\n\n")
        
        f.write("√ÅREA (KIL√ìMETROS CUADRADOS):\n")
        f.write("-"*70 + "\n")
        f.write(f"√Årea total (v√°lida):    {area_total_ha/100:,.2f} km¬≤\n")
        f.write(f"√Årea de Manglar:        {area_manglar_ha/100:,.2f} km¬≤\n")
        f.write(f"√Årea de No-Manglar:     {area_no_manglar_ha/100:,.2f} km¬≤\n")
        f.write("-"*70 + "\n\n")
        
        f.write("INTERPRETACI√ìN:\n")
        f.write("-"*70 + "\n")
        f.write(f"El √°rea de estudio para el a√±o {year} cubre aproximadamente\n")
        f.write(f"{area_total_ha:,.0f} hect√°reas ({area_total_ha/100:,.1f} km¬≤).\n\n")
        f.write(f"Se detectaron {area_manglar_ha:,.0f} hect√°reas de manglar,\n")
        f.write(f"lo que representa el {manglar_pct:.1f}% del √°rea total analizada.\n")
        f.write("="*70 + "\n")
    
    print(f"‚úÖ Reporte de √°rea guardado: {output_report_path}")
    print(f"\nüìä Resumen:")
    print(f"   √Årea total:      {area_total_ha:,.2f} ha ({area_total_ha/100:,.2f} km¬≤)")
    print(f"   √Årea de Manglar: {area_manglar_ha:,.2f} ha ({manglar_pct:.2f}%)")




#====================================
# üé® VISUALIZACI√ìN COMPARATIVA 3√ó5
#====================================

def generate_comparative_visualization_3x5(
    checkpoint_path,
    images_dir,
    masks_dir,
    output_dir,
    device='cpu',
    threshold=0.5,
    year=2021
):
    """
    Genera visualizaci√≥n comparativa 3√ó5 de escenarios representativos.

    Estructura:
    - Filas: [Imagen Original, M√°scara Real, M√°scara Predicha]
    - Columnas: [Alta cobertura, Baja cobertura, Media homog√©nea, Fragmentaci√≥n, Alternancia compleja]

    Args:
        checkpoint_path: Ruta al modelo entrenado
        images_dir: Directorio con im√°genes de test
        masks_dir: Directorio con m√°scaras ground truth
        output_dir: Directorio de salida
        device: Dispositivo ('cpu', 'cuda', 'mps')
        threshold: Umbral para binarizaci√≥n
        year: A√±o de an√°lisis
    """
    from scipy import ndimage

    print("\nüé® Generando visualizaci√≥n comparativa 3√ó5...")

    # Cargar modelo
    module = load_model(checkpoint_path, device)

    # Buscar tiles y m√°scaras
    tile_paths = sorted(images_dir.glob("*.tif"))

    if len(tile_paths) == 0:
        print("‚ö†Ô∏è  No se encontraron tiles para visualizaci√≥n")
        return

    # Funci√≥n auxiliar: calcular IoU
    def calc_iou(pred, target, thresh=0.5):
        pred_bin = (pred > thresh).astype(np.uint8)
        target_bin = target.astype(np.uint8)

        intersection = np.logical_and(pred_bin, target_bin).sum()
        union = np.logical_or(pred_bin, target_bin).sum()

        if union == 0:
            return 1.0 if intersection == 0 else 0.0

        return intersection / union

    # Funci√≥n auxiliar: clasificar escenario
    def classify_scenario(mask):
        total_pixels = mask.size
        manglar_pixels = np.sum(mask == 1)
        manglar_pct = (manglar_pixels / total_pixels) * 100

        # Calcular fragmentaci√≥n
        labeled_array, num_features = ndimage.label(mask)

        if manglar_pct > 70:
            return "high_coverage", manglar_pct
        elif manglar_pct < 10:
            return "low_coverage", manglar_pct
        elif 30 <= manglar_pct <= 50 and num_features < 5:
            return "medium_homogeneous", manglar_pct
        elif num_features > 10:
            return "high_fragmentation", manglar_pct
        else:
            return "complex_alternation", manglar_pct

    # Buscar tiles representativos
    print("  üîç Buscando tiles representativos...")

    scenarios = ["high_coverage", "low_coverage", "medium_homogeneous",
                "high_fragmentation", "complex_alternation"]
    scenario_candidates = {s: [] for s in scenarios}

    for tile_path in tqdm(tile_paths, desc="  Escaneando tiles"):
        # Buscar m√°scara correspondiente
        # Para archivos como: 2021_Sentinel-2_r010_c013.tif
        # Generar m√°scara: 2021_Sentinel-2_mask_r010_c013.tif
        mask_name = tile_path.name.replace('Sentinel-2_', 'Sentinel-2_mask_')
        mask_path = masks_dir / mask_name

        if not mask_path.exists():
            continue

        try:
            with rasterio.open(mask_path) as src:
                mask = src.read(1)

            scenario_type, manglar_pct = classify_scenario(mask)
            scenario_candidates[scenario_type].append({
                'tile_path': tile_path,
                'mask_path': mask_path,
                'manglar_pct': manglar_pct
            })
        except:
            continue

    # Seleccionar candidatos de manera aleatoria
    import random
    selected = {}

    for scenario in scenarios:
        candidates = scenario_candidates[scenario]

        if len(candidates) == 0:
            continue

        # Filtrar candidatos dentro de rangos √≥ptimos y seleccionar aleatoriamente
        if scenario == "high_coverage":
            # Preferir tiles con 75-85% de manglar, pero aceptar >70%
            optimal = [c for c in candidates if 75 <= c['manglar_pct'] <= 85]
            pool = optimal if len(optimal) > 0 else candidates
        elif scenario == "low_coverage":
            # Preferir tiles con 3-8% de manglar, pero aceptar <10%
            optimal = [c for c in candidates if 3 <= c['manglar_pct'] <= 8]
            pool = optimal if len(optimal) > 0 else candidates
        elif scenario == "medium_homogeneous":
            # Preferir tiles con 35-45% de manglar
            optimal = [c for c in candidates if 35 <= c['manglar_pct'] <= 45]
            pool = optimal if len(optimal) > 0 else candidates
        else:
            # Para fragmentaci√≥n y alternancia, todos los candidatos son v√°lidos
            pool = candidates

        # Seleccionar aleatoriamente del pool
        best = random.choice(pool)
        selected[scenario] = best
        print(f"  ‚úì {scenario}: {best['tile_path'].name} ({best['manglar_pct']:.1f}% manglar)")

    if len(selected) < 5:
        print(f"  ‚ö†Ô∏è  Solo se encontraron {len(selected)}/5 escenarios")
        # Completar con aleatorios
        for scenario in scenarios:
            if scenario not in selected and len(tile_paths) > 0:
                rand_tile = random.choice(tile_paths)
                rand_mask = masks_dir / rand_tile.name.replace('Sentinel-2_', 'Sentinel-2_mask_')
                if rand_mask.exists():
                    selected[scenario] = {
                        'tile_path': rand_tile,
                        'mask_path': rand_mask,
                        'manglar_pct': 0
                    }

    # Generar predicciones y preparar datos
    print("  üîÆ Generando predicciones...")

    images = []
    masks_gt = []
    masks_pred = []
    ious = []
    scenario_names = []

    for scenario in scenarios:
        if scenario not in selected:
            continue

        tile_info = selected[scenario]

        # Leer imagen
        with rasterio.open(tile_info['tile_path']) as src:
            image = src.read()  # [C, H, W]

        # RGB (bandas 2,1,0 para B4,B3,B2)
        rgb = np.stack([image[2], image[1], image[0]], axis=-1)  # [H, W, 3]

        # Reemplazar NaN con 0 (√°reas sin datos)
        rgb = np.nan_to_num(rgb, nan=0.0, posinf=1.0, neginf=0.0)

        # Aplicar percentile stretch POR BANDA individual para mejor contraste
        # Esto es crucial para tiles con baja cobertura o caracter√≠sticas espec√≠ficas
        rgb_enhanced = np.zeros_like(rgb)

        for i in range(3):  # Para cada banda RGB
            band = rgb[:, :, i]

            # Filtrar valores v√°lidos (no cero) para c√°lculo de percentiles
            valid_pixels = band[band > 0]

            if len(valid_pixels) > 10:  # Si hay suficientes p√≠xeles v√°lidos
                # Calcular percentiles solo sobre p√≠xeles v√°lidos
                p2 = np.percentile(valid_pixels, 2)
                p98 = np.percentile(valid_pixels, 98)

                # Evitar divisi√≥n por cero
                if p98 - p2 > 1e-6:
                    # Aplicar stretch lineal a esta banda
                    band_stretched = (band - p2) / (p98 - p2)
                    band_stretched = np.clip(band_stretched, 0, 1)
                else:
                    # Si el rango es muy peque√±o, usar normalizaci√≥n simple
                    max_val = valid_pixels.max()
                    if max_val > 1e-6:
                        band_stretched = band / max_val
                    else:
                        band_stretched = band
                    band_stretched = np.clip(band_stretched, 0, 1)
            else:
                # Si no hay suficientes p√≠xeles v√°lidos, normalizar todo
                max_val = band.max()
                if max_val > 1e-6:
                    band_stretched = band / max_val
                else:
                    band_stretched = np.zeros_like(band)
                band_stretched = np.clip(band_stretched, 0, 1)

            rgb_enhanced[:, :, i] = band_stretched

        # Aplicar gamma correction m√°s agresiva para mejorar brillo
        rgb = np.power(rgb_enhanced, 0.6)  # Gamma m√°s bajo = imagen m√°s clara

        # Leer m√°scara
        with rasterio.open(tile_info['mask_path']) as src:
            mask = src.read(1)

        # Generar predicci√≥n
        pred_binary, _, _, _, _ = predict_tile(
            module,
            str(tile_info['tile_path']),
            device=device,
            threshold=threshold
        )

        # Calcular IoU
        iou = calc_iou(pred_binary, mask, threshold)

        images.append(rgb)
        masks_gt.append(mask)
        masks_pred.append(pred_binary)
        ious.append(iou)
        scenario_names.append(scenario)

    # Crear visualizaci√≥n
    print("  üñºÔ∏è  Creando figura 3√ó5...")

    scenario_labels = {
        'high_coverage': '(a) Cobertura Alta\n(>70% manglar)',
        'low_coverage': '(b) Cobertura Baja\n(<10% manglar)',
        'medium_homogeneous': '(c) Media Homog√©nea\n(30-50%)',
        'high_fragmentation': '(d) Fragmentaci√≥n Alta\n(>10 parches)',
        'complex_alternation': '(e) Alternancia Compleja'
    }

    fig, axes = plt.subplots(3, len(images), figsize=(4*len(images), 12))

    if len(images) == 1:
        axes = axes.reshape(3, 1)

    fig.suptitle(f'Visualizaci√≥n Comparativa: Escenarios Representativos de Segmentaci√≥n ({year})',
                 fontsize=16, fontweight='bold', y=0.98)

    for col, (img, mask_gt, mask_pred, iou, scen) in enumerate(
        zip(images, masks_gt, masks_pred, ious, scenario_names)
    ):
        # Fila 1: Imagen
        axes[0, col].imshow(img)
        axes[0, col].set_title(scenario_labels.get(scen, scen),
                              fontsize=13, fontweight='bold')
        axes[0, col].axis('off')

        # Fila 2: Ground truth
        axes[1, col].imshow(mask_gt, cmap='RdYlGn', vmin=0, vmax=1)
        axes[1, col].set_title('Ground Truth', fontsize=13)
        axes[1, col].axis('off')

        manglar_pct = (np.sum(mask_gt == 1) / mask_gt.size) * 100
        axes[1, col].text(0.5, -0.15, f'{manglar_pct:.1f}% manglar',
                         ha='center', va='top', transform=axes[1, col].transAxes,
                         fontsize=12, style='italic')

        # Fila 3: Predicci√≥n
        axes[2, col].imshow(mask_pred, cmap='RdYlGn', vmin=0, vmax=1)
        axes[2, col].set_title(f'Predicci√≥n (IoU: {iou:.3f})',
                              fontsize=13, fontweight='bold')
        axes[2, col].axis('off')

        color = 'green' if iou > 0.85 else ('orange' if iou > 0.70 else 'red')
        axes[2, col].title.set_color(color)

    # Etiquetas de filas
    row_labels = ['Imagen Satelital', 'Ground Truth', 'Predicci√≥n']
    for row, label in enumerate(row_labels):
        axes[row, 0].text(-0.25, 0.5, label, rotation=90, va='center', ha='center',
                         transform=axes[row, 0].transAxes, fontsize=14, fontweight='bold')

    # Leyenda
    import matplotlib.patches as mpatches
    legend = [
        mpatches.Patch(facecolor='#4CAF50', edgecolor='black', label='Manglar (1)'),
        mpatches.Patch(facecolor='#8B4513', edgecolor='black', label='No Manglar (0)')
    ]
    fig.legend(handles=legend, loc='lower center', ncol=2, fontsize=13,
              frameon=True, bbox_to_anchor=(0.5, -0.02))

    plt.tight_layout(rect=[0.05, 0.02, 1, 0.96])

    # Guardar
    output_path = Path(output_dir) / f'visualizacion_comparativa_3x5_{year}.jpg'
    output_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(output_path, dpi=300, bbox_inches='tight', format='png')
    plt.close()

    print(f"\n  ‚úÖ Visualizaci√≥n guardada en: {output_path}")
    print(f"  üìä IoU promedio: {np.mean(ious):.3f}")

    return output_path


#====================================
# CLASE: GENERADOR DE FALSO COLOR
#====================================

class FalseColorMosaicGenerator:
    """
    Generador de mosaicos de falso color para resaltar vegetaci√≥n.

    Genera visualizaciones de falso color usando combinaciones espectrales:
    - Falso Color Infrarrojo: RGB = NIR, Red, Green (resalta vegetaci√≥n en rojo)
    - Falso Color Agricultura: RGB = SWIR1, NIR, Blue (resalta salud vegetal)

    Aplica contorno del √°rea de estudio y elementos cartogr√°ficos.
    """

    def __init__(self, year: int, images_dir: Path, output_dir: Path,
                 shapefile_path: Path):
        """
        Args:
            year: A√±o de an√°lisis
            images_dir: Directorio con im√°genes Sentinel-2 originales
            output_dir: Directorio de salida para mosaicos
            shapefile_path: Ruta al shapefile del √°rea de estudio
        """
        self.year = year
        self.images_dir = images_dir
        self.output_dir = output_dir
        self.shapefile_path = shapefile_path

        # Bandas Sentinel-2 disponibles en las teselas
        self.band_names = ['Blue', 'Green', 'Red', 'NIR', 'SWIR1', 'SWIR2']
        self.band_indices = {
            'Blue': 0,   # B2
            'Green': 1,  # B3
            'Red': 2,    # B4
            'NIR': 3,    # B8
            'SWIR1': 4,  # B11
            'SWIR2': 5   # B12
        }

        # Leer shapefile
        print(f"üìÇ Cargando shapefile: {self.shapefile_path.name}")
        self.gdf = gpd.read_file(self.shapefile_path)
        print(f"   CRS: {self.gdf.crs}")
        print(f"   Geometr√≠as: {len(self.gdf)}")

    def create_spectral_mosaic(self):
        """
        Crea mosaico conservando todas las bandas espectrales.

        Returns:
            Tupla (mosaic_path, mosaic, out_transform, crs)
        """
        print(f"\nüß© Creando mosaico espectral (6 bandas)...")

        # Buscar todas las teselas
        tile_files = sorted(self.images_dir.glob("*.tif"))
        print(f"   Encontradas {len(tile_files)} teselas")

        if len(tile_files) == 0:
            raise ValueError(f"No se encontraron teselas en {self.images_dir}")

        # Leer primera tesela para obtener metadatos
        with rasterio.open(tile_files[0]) as src:
            crs = src.crs
            dtype = src.dtypes[0]
            count = src.count

        print(f"   Bandas: {count}")
        print(f"   CRS: {crs}")

        # Crear mosaico usando merge
        print(f"   Merging teselas...")
        src_files_to_mosaic = []
        for tile in tqdm(tile_files, desc="Abriendo teselas"):
            src = rasterio.open(tile)
            src_files_to_mosaic.append(src)

        mosaic, out_transform = merge(src_files_to_mosaic, method='first')

        # Cerrar archivos
        for src in src_files_to_mosaic:
            src.close()

        # Metadatos del mosaico
        out_meta = {
            'driver': 'GTiff',
            'height': mosaic.shape[1],
            'width': mosaic.shape[2],
            'count': mosaic.shape[0],
            'dtype': dtype,
            'crs': crs,
            'transform': out_transform,
            'compress': 'lzw'
        }

        # Guardar mosaico temporal
        mosaic_path = self.output_dir / f'mosaico_espectral_{self.year}.tif'
        with rasterio.open(mosaic_path, 'w', **out_meta) as dest:
            dest.write(mosaic)

        print(f"   ‚úÖ Mosaico espectral creado: {mosaic_path.name}")
        print(f"   Dimensiones: {mosaic.shape[2]} x {mosaic.shape[1]} p√≠xeles")
        print(f"   Bandas: {mosaic.shape[0]}")

        return mosaic_path, mosaic, out_transform, crs

    def apply_study_area_mask_to_mosaic(self, mosaic, transform, crs):
        """
        Recorta el mosaico al √°rea de estudio usando el shapefile.

        Args:
            mosaic: Array del mosaico [bands, height, width]
            transform: Transformaci√≥n espacial
            crs: CRS del mosaico

        Returns:
            Tupla (mosaico_recortado, m√°scara_binaria, transform_ajustado)
        """
        print(f"\nüó∫Ô∏è  Recortando mosaico al √°rea de estudio...")

        # PASO 1: Reproyectar shapefile si es necesario
        if self.gdf.crs != crs:
            print(f"   Reproyectando shapefile de {self.gdf.crs} a {crs}")
            gdf = self.gdf.to_crs(crs)
        else:
            gdf = self.gdf

        # PASO 2: Crear dataset en memoria para aplicar rasterio.mask
        from rasterio.io import MemoryFile

        # Metadatos temporales
        meta = {
            'driver': 'GTiff',
            'height': mosaic.shape[1],
            'width': mosaic.shape[2],
            'count': mosaic.shape[0],
            'dtype': mosaic.dtype,
            'crs': crs,
            'transform': transform
        }

        # Usar MemoryFile para aplicar m√°scara sin escribir a disco
        with MemoryFile() as memfile:
            with memfile.open(**meta) as dataset:
                dataset.write(mosaic)

                # Aplicar m√°scara con crop=True para recortar al shapefile
                out_image, out_transform = rasterio_mask(
                    dataset,
                    gdf.geometry,
                    crop=True,        # CR√çTICO: Recortar al bounding box del shapefile
                    filled=True,
                    nodata=0,
                    all_touched=True  # Incluir p√≠xeles que tocan el shapefile
                )

        print(f"   Mosaico recortado: {out_image.shape[2]}x{out_image.shape[1]} p√≠xeles")

        # PASO 3: Crear m√°scara binaria para el √°rea recortada
        from rasterio.features import rasterize
        mask = rasterize(
            [(geom, 1) for geom in gdf.geometry],
            out_shape=(out_image.shape[1], out_image.shape[2]),
            transform=out_transform,
            fill=0,
            dtype=np.uint8,
            all_touched=True
        )

        pixels_inside = np.sum(mask > 0)
        pixels_total = mask.size
        print(f"   P√≠xeles dentro del √°rea: {pixels_inside:,} ({100*pixels_inside/pixels_total:.1f}% del recorte)")

        return out_image, mask, out_transform

    def _add_scale_bar(self, ax, left, right, bottom, top):
        """A√±ade barra de escala cartogr√°fica."""
        # Calcular longitud de barra apropiada
        extent_width = right - left
        scale_length_m = 10000  # 10 km por defecto

        # Ajustar si el √°rea es m√°s peque√±a
        if extent_width < 30000:
            scale_length_m = 5000  # 5 km

        # Posici√≥n de la barra (centrada en la parte superior)
        center_x = (left + right) / 2
        bar_x = center_x - scale_length_m / 2
        bar_y = top - 2500  # 2.5 km del borde superior

        # Dibujar fondo de la barra (negro)
        ax.plot([bar_x, bar_x + scale_length_m], [bar_y, bar_y],
               color='black', linewidth=6, solid_capstyle='butt', zorder=12)

        # Dibujar barra principal (blanco)
        ax.plot([bar_x, bar_x + scale_length_m], [bar_y, bar_y],
               color='white', linewidth=4, solid_capstyle='butt', zorder=13)

        # Marcar segmentos (cada 1/4 de la barra)
        segment_length = scale_length_m / 4
        for i in range(5):
            x_pos = bar_x + i * segment_length
            ax.plot([x_pos, x_pos], [bar_y - 150, bar_y + 150],
                   color='white', linewidth=2, zorder=13)

        # Etiquetas de distancia
        label_km = scale_length_m / 1000
        ax.text(bar_x, bar_y - 600, '0', ha='center', va='top',
               color='white', fontsize=8, weight='bold',
               bbox=dict(boxstyle='round,pad=0.3', facecolor='black', alpha=0.7),
               zorder=14)
        ax.text(bar_x + scale_length_m, bar_y - 600, f'{label_km:.0f} km',
               ha='center', va='top',
               color='white', fontsize=8, weight='bold',
               bbox=dict(boxstyle='round,pad=0.3', facecolor='black', alpha=0.7),
               zorder=14)

    def _add_north_arrow(self, ax):
        """A√±ade flecha de norte discreta."""
        # Posici√≥n en el lado izquierdo
        arrow_x = 0.05
        arrow_y = 0.70

        # Fondo negro para contraste
        ax.annotate('', xy=(arrow_x, arrow_y), xycoords='axes fraction',
                   xytext=(arrow_x, arrow_y - 0.06),
                   arrowprops=dict(arrowstyle='->', lw=4, color='black',
                                 mutation_scale=20),
                   zorder=13)

        # Flecha blanca
        ax.annotate('', xy=(arrow_x, arrow_y), xycoords='axes fraction',
                   xytext=(arrow_x, arrow_y - 0.06),
                   arrowprops=dict(arrowstyle='->', lw=2.5, color='white',
                                 mutation_scale=20),
                   zorder=14)

        # Etiqueta "N"
        ax.text(arrow_x, arrow_y + 0.015, 'N',
               transform=ax.transAxes,
               ha='center', va='bottom',
               fontsize=12, weight='bold', color='white',
               bbox=dict(boxstyle='circle,pad=0.3', facecolor='black',
                        alpha=0.75, edgecolor='white', linewidth=1.5),
               zorder=14)

    def generate_false_color_visualization(self, mosaic, mask, transform, crs,
                                          color_scheme='infrared'):
        """
        Genera visualizaci√≥n de falso color.

        Args:
            mosaic: Mosaico espectral [bands, height, width]
            mask: M√°scara binaria del √°rea de estudio
            transform: Transformaci√≥n espacial
            crs: CRS del mosaico
            color_scheme: 'infrared' o 'agriculture'

        Returns:
            Ruta a la imagen generada
        """
        print(f"\nüé® Generando falso color ({color_scheme})...")

        # Seleccionar bandas seg√∫n esquema
        if color_scheme == 'infrared':
            # RGB = NIR, Red, Green
            band_r = self.band_indices['NIR']
            band_g = self.band_indices['Red']
            band_b = self.band_indices['Green']
            title = f'Falso Color Infrarrojo - Vegetaci√≥n (A√±o {self.year})'
            filename = f'falso_color_infrarrojo_{self.year}.png'
        elif color_scheme == 'agriculture':
            # RGB = SWIR1, NIR, Blue
            band_r = self.band_indices['SWIR1']
            band_g = self.band_indices['NIR']
            band_b = self.band_indices['Blue']
            title = f'Falso Color Agricultura (A√±o {self.year})'
            filename = f'falso_color_agricultura_{self.year}.png'
        else:
            raise ValueError(f"Esquema de color no v√°lido: {color_scheme}")

        # Extraer bandas
        r_band = mosaic[band_r].astype(np.float32)
        g_band = mosaic[band_g].astype(np.float32)
        b_band = mosaic[band_b].astype(np.float32)

        print(f"   Bandas seleccionadas:")
        print(f"   R: {self.band_names[band_r]}")
        print(f"   G: {self.band_names[band_g]}")
        print(f"   B: {self.band_names[band_b]}")

        # Crear composici√≥n RGB
        rgb = np.stack([r_band, g_band, b_band], axis=-1)

        # Filtrar solo p√≠xeles v√°lidos
        valid_mask = mask > 0

        # Percentile stretch por banda
        print(f"   Aplicando percentile stretch (2-98%)...")
        for i in range(3):
            band = rgb[:, :, i]
            valid_pixels = band[valid_mask]

            if len(valid_pixels) > 0:
                valid_pixels = valid_pixels[valid_pixels > 0]

                if len(valid_pixels) > 10:
                    p2 = np.percentile(valid_pixels, 2)
                    p98 = np.percentile(valid_pixels, 98)

                    if p98 - p2 > 1e-6:
                        band_stretched = (band - p2) / (p98 - p2)
                        band_stretched = np.clip(band_stretched, 0, 1)
                    else:
                        band_stretched = band / (np.max(band) + 1e-6)
                        band_stretched = np.clip(band_stretched, 0, 1)

                    rgb[:, :, i] = band_stretched

        # Gamma correction diferenciado
        print(f"   Aplicando gamma correction diferenciado...")
        if color_scheme == 'infrared':
            gamma_r = 0.65  # NIR - vegetaci√≥n m√°s brillante
            gamma_g = 0.75  # Red
            gamma_b = 0.75  # Green
            rgb[:, :, 0] = np.power(rgb[:, :, 0], gamma_r)
            rgb[:, :, 1] = np.power(rgb[:, :, 1], gamma_g)
            rgb[:, :, 2] = np.power(rgb[:, :, 2], gamma_b)
        else:
            gamma = 0.7
            rgb = np.power(rgb, gamma)

        # Crear figura
        print(f"   Creando visualizaci√≥n...")
        height, width = rgb.shape[:2]
        aspect_ratio = width / height
        fig_width = 18
        fig_height = fig_width / aspect_ratio
        fig, ax = plt.subplots(figsize=(fig_width, fig_height))

        # Calcular extent
        left, bottom, right, top = rasterio.transform.array_bounds(
            height, width, transform
        )

        # Fondo celeste claro para agua
        ax.set_facecolor('#87CEEB')

        # Convertir RGB a RGBA para transparencia
        rgba = np.zeros((height, width, 4), dtype=rgb.dtype)
        rgba[:, :, :3] = rgb
        alpha = np.any(rgb > 0.01, axis=2).astype(rgb.dtype)
        rgba[:, :, 3] = alpha

        # Mostrar imagen
        ax.imshow(rgba, extent=[left, right, bottom, top],
                 interpolation='bilinear', aspect='equal')

        # Superponer contorno del shapefile
        if self.gdf.crs != crs:
            gdf_plot = self.gdf.to_crs(crs)
        else:
            gdf_plot = self.gdf

        # Contorno doble (negro + amarillo)
        gdf_plot.boundary.plot(ax=ax, color='black', linewidth=2.5,
                              linestyle='-', alpha=0.9, zorder=10)
        gdf_plot.boundary.plot(ax=ax, color='#FFD700', linewidth=1.5,
                              linestyle='-', alpha=1.0, zorder=11,
                              label='L√≠mite del √°rea de estudio')

        # L√≠mites del gr√°fico
        ax.set_xlim(left, right)
        ax.set_ylim(bottom, top)

        # T√≠tulos y etiquetas
        ax.set_title(title, fontsize=18, fontweight='bold', pad=15)
        ax.set_xlabel('Longitud (m)', fontsize=12)
        ax.set_ylabel('Latitud (m)', fontsize=12)

        # Leyenda superior derecha
        ax.legend(loc='upper right', fontsize=9, framealpha=0.9,
                 fancybox=True, shadow=True, edgecolor='black')

        # Grid sutil
        ax.grid(True, alpha=0.15, linestyle=':', linewidth=0.3, color='white')

        # Caja de informaci√≥n
        if color_scheme == 'infrared':
            composition = "RGB = NIR, Red, Green"
        else:
            composition = "RGB = SWIR1, NIR, Blue"

        info_lines = [
            "Composici√≥n Espectral:",
            f"  {composition}",
            "",
            "√Årea de Estudio:",
            "  Archipi√©lago de Jambel√≠",
            "",
            "Resoluci√≥n Espacial:",
            "  10 m/p√≠xel"
        ]
        info_text = "\n".join(info_lines)

        ax.text(0.98, 0.02, info_text,
               transform=ax.transAxes,
               fontsize=9,
               verticalalignment='bottom',
               horizontalalignment='right',
               family='monospace',
               bbox=dict(boxstyle='round,pad=0.6', facecolor='black', alpha=0.75,
                        edgecolor='#FFD700', linewidth=1.5),
               color='white',
               zorder=15)

        # A√±adir barra de escala y flecha norte
        self._add_scale_bar(ax, left, right, bottom, top)
        self._add_north_arrow(ax)

        plt.tight_layout()
        plt.subplots_adjust(left=0.1, right=0.95, top=0.95, bottom=0.1)

        # Guardar
        output_path = self.output_dir / filename
        plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white',
                   pad_inches=0.2)
        plt.close()

        print(f"   ‚úÖ Falso color guardado: {filename}")
        return output_path

    def generate_all_false_color_images(self):
        """Genera todos los mosaicos de falso color."""

        print("="*80)
        print(f"üåà GENERACI√ìN DE MOSAICOS DE FALSO COLOR - A√ëO {self.year}")
        print("="*80)

        # Paso 1: Crear mosaico espectral
        mosaic_path, mosaic, transform, crs = self.create_spectral_mosaic()

        # Paso 2: Aplicar m√°scara del √°rea de estudio
        mosaic_masked, mask, transform_cropped = self.apply_study_area_mask_to_mosaic(
            mosaic, transform, crs
        )

        # Paso 3: Generar visualizaciones de falso color
        paths = []

        # 3.1 Falso Color Infrarrojo
        path_infrared = self.generate_false_color_visualization(
            mosaic_masked, mask, transform_cropped, crs,
            color_scheme='infrared'
        )
        paths.append(path_infrared)

        # 3.2 Falso Color Agricultura
        path_agriculture = self.generate_false_color_visualization(
            mosaic_masked, mask, transform_cropped, crs,
            color_scheme='agriculture'
        )
        paths.append(path_agriculture)

        print("\n" + "="*80)
        print("‚úÖ MOSAICOS DE FALSO COLOR GENERADOS EXITOSAMENTE")
        print("="*80)
        print(f"\nArchivos generados en: {self.output_dir}")
        for path in paths:
            print(f"  ‚Ä¢ {path.name}")

        return paths


#====================================
# FUNCI√ìN: PIPELINE PRINCIPAL
#====================================

def run_pipeline(year, base_dir, checkpoint_path, output_base_dir='predicciones',
                 threshold=0.5, use_postproc=True, postproc_mode='conservative'):
    """
    Ejecuta el pipeline completo para un a√±o espec√≠fico
    
    Args:
        year: A√±o de an√°lisis (ej: 2021, 2022, 2023)
        base_dir: Directorio base con carpetas Manglar_[A√ëO]_*
        checkpoint_path: Ruta al checkpoint del modelo
        output_base_dir: Directorio base para outputs
        threshold: Umbral de decisi√≥n (0.0-1.0)
        use_postproc: Activar post-procesamiento morfol√≥gico
        postproc_mode: Modo post-proc ('conservative', 'moderate', 'none')
    """
    
    print("="*80)
    print(f"üå≥ PIPELINE DE AN√ÅLISIS DE MANGLARES - A√ëO {year}")
    print("="*80)
    
    # Limpieza autom√°tica de directorio anterior
    import shutil
    output_year_dir = Path(output_base_dir) / f"year_{year}"
    if output_year_dir.exists():
        print(f"\nüóëÔ∏è  Limpiando directorio anterior: {output_year_dir}")
        print(f"   (Para forzar regeneraci√≥n con nuevo threshold)")
        try:
            shutil.rmtree(output_year_dir)
            print(f"   ‚úÖ Directorio eliminado correctamente")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Error al eliminar: {e}")
            print(f"   Por favor, elimina manualmente: rm -rf {output_year_dir}")
    
    # ====================================
    # CONFIGURACI√ìN POR A√ëO
    # ====================================
    
    config = YearConfig(
        year=year,
        base_dir=base_dir,
        checkpoint_path=checkpoint_path,
        output_base_dir=output_base_dir
    )
    
    print("\nüìã CONFIGURACI√ìN:")
    print("-"*80)
    for key, value in config.get_summary().items():
        print(f"   {key}: {value}")
    print(f"   Threshold para binarizaci√≥n: {threshold}")
    print(f"   Post-procesamiento morfol√≥gico: {'S√ç' if use_postproc else 'NO'}")
    if use_postproc:
        print(f"   Modo post-procesamiento: {postproc_mode}")
    print("-"*80)
    
    # Detectar dispositivo
    if torch.cuda.is_available():
        device = 'cuda'
    elif torch.backends.mps.is_available():
        device = 'mps'
    else:
        device = 'cpu'
    
    print(f"\nüíª Dispositivo: {device.upper()}")
    
    # ====================================
    # PASO 1: PREDICCI√ìN DE TESELAS
    # ====================================
    
    print("\n" + "="*80)
    print(f"PASO 1: PREDICCI√ìN DE TESELAS - A√ëO {year}")
    print("="*80)
    
    pred_files = process_tiles(
        checkpoint_path=config.checkpoint_path,
        images_dir=config.images_dir,
        output_dir=config.predictions_dir,
        device=device,
        threshold=threshold,
        use_postproc=use_postproc,
        postproc_mode=postproc_mode
    )
    
    if len(pred_files) == 0:
        print("\n‚ùå No se generaron predicciones. Abortando...")
        return
    
    # ====================================
    # PASO 2: MATRIZ DE CONFUSI√ìN
    # ====================================
    
    print("\n" + "="*80)
    print(f"PASO 2: C√ÅLCULO DE MATRIZ DE CONFUSI√ìN - A√ëO {year}")
    print("="*80)
    
    cm, metrics, valid_count = calculate_confusion_matrix_from_files(pred_files, config.masks_dir)
    
    if cm is not None and metrics is not None:
        # Guardar matriz de confusi√≥n
        cm_path = config.metrics_dir / 'confusion_matrix.png'
        plot_confusion_matrix_for_article(cm, metrics, str(cm_path), year)
        
        # Guardar gr√°fico de m√©tricas
        metrics_plot_path = config.metrics_dir / 'metricas_rendimiento.png'
        plot_metrics_comparison(metrics, str(metrics_plot_path), year)
        
        # Guardar reporte detallado
        report_path = config.metrics_dir / 'reporte_metricas.txt'
        save_confusion_matrix_report(cm, metrics, str(report_path), year)
        
        # Guardar m√©tricas en JSON
        json_path = config.metrics_dir / 'metricas.json'
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(metrics, f, indent=4, ensure_ascii=False)
        print(f"‚úÖ M√©tricas JSON guardadas: {json_path}")
        
        # Mostrar resumen en consola
        print("\n" + "="*80)
        print(f"üìä RESUMEN DE M√âTRICAS - A√ëO {year}")
        print("="*80)
        print(f"Teselas evaluadas:     {metrics['tiles_evaluated']}")
        print(f"True Positives (TP):   {metrics['TP']:>15,} p√≠xeles")
        print(f"True Negatives (TN):   {metrics['TN']:>15,} p√≠xeles")
        print(f"False Positives (FP):  {metrics['FP']:>15,} p√≠xeles")
        print(f"False Negatives (FN):  {metrics['FN']:>15,} p√≠xeles")
        print(f"\nAccuracy:              {metrics['accuracy']:>15.4f} ({metrics['accuracy']*100:.2f}%)")
        print(f"Precision:             {metrics['precision']:>15.4f} ({metrics['precision']*100:.2f}%)")
        print(f"Recall:                {metrics['recall']:>15.4f} ({metrics['recall']*100:.2f}%)")
        print(f"F1-Score:              {metrics['f1_score']:>15.4f}")
        print(f"Mean IoU:              {metrics['mean_iou']:>15.4f}")
        print("="*80)
    else:
        print(f"\n‚ö†Ô∏è No se pudo calcular la matriz de confusi√≥n para el a√±o {year}.")
        print("   Continuando con la creaci√≥n del mosaico...")

    # ====================================
    # PASO 2.5: AN√ÅLISIS AVANZADO Y CURVA ROC
    # ====================================

    print("\n" + "="*80)
    print(f"PASO 2.5: AN√ÅLISIS AVANZADO Y CURVA ROC - A√ëO {year}")
    print("="*80)

    advanced_metrics = generate_advanced_analysis_plots(
        predictions_dir=config.predictions_dir,
        masks_dir=config.masks_dir,
        output_dir=config.metrics_dir,
        year=year,
        threshold=threshold
    )

    # ====================================
    # PASO 3: CREACI√ìN DE MOSAICO
    # ====================================
    
    print("\n" + "="*80)
    print(f"PASO 3: CREACI√ìN DE MOSAICO - A√ëO {year}")
    print("="*80)
    
    mosaic_path = config.mosaic_dir / f'mosaico_manglares_{year}.tif'
    
    create_mosaic(
        pred_files=pred_files,
        output_mosaic_path=str(mosaic_path),
        method='first'
    )

    # ====================================
    # PASO 3.5: APLICAR M√ÅSCARA DEL √ÅREA DE ESTUDIO
    # ====================================

    print("\n" + "="*80)
    print(f"PASO 3.5: APLICAR CONTORNO DEL √ÅREA DE ESTUDIO - A√ëO {year}")
    print("="*80)

    # Ruta al shapefile del √°rea de estudio (Jambeli)
    shapefile_path = Path('/Users/elvissanchez/Documents/GitHub/thesis_project/data/archive_Shape/Jambeli_corregido/Area_Estudio_Jambeli.shp')

    if shapefile_path.exists():
        # Aplicar m√°scara (sobrescribe el mosaico original)
        mosaic_path = apply_study_area_mask(
            mosaic_path=str(mosaic_path),
            shapefile_path=str(shapefile_path),
            output_path=None  # Sobrescribe el original
        )
    else:
        print(f"‚ö†Ô∏è  Shapefile no encontrado: {shapefile_path}")
        print("   Continuando sin aplicar m√°scara del √°rea de estudio...")

    # ====================================
    # PASO 4: VISUALIZACI√ìN
    # ====================================
    
    print("\n" + "="*80)
    print(f"PASO 4: VISUALIZACI√ìN DEL MOSAICO - A√ëO {year}")
    print("="*80)

    viz_path = config.mosaic_dir / f'mosaico_visualizacion_{year}.png'

    # Ruta al shapefile (misma que se usa en PASO 3.5)
    shapefile_path_viz = Path('/Users/elvissanchez/Documents/GitHub/thesis_project/data/archive_Shape/Jambeli_corregido/Area_Estudio_Jambeli.shp')

    visualize_mosaic(
        mosaic_path=str(mosaic_path),
        output_viz_path=str(viz_path),
        year=year,
        figsize=(20, 16),
        dpi=300,
        shapefile_path=str(shapefile_path_viz) if shapefile_path_viz.exists() else None
    )

    # ====================================
    # PASO 4.5: VISUALIZACIONES INDIVIDUALES DE TESELAS
    # ====================================

    print("\n" + "="*80)
    print(f"PASO 4.5: VISUALIZACIONES INDIVIDUALES - A√ëO {year}")
    print("="*80)

    # Generar visualizaciones comparativas (RGB | GT | Pred)
    viz_count = generate_tile_visualizations(
        images_dir=config.images_dir,
        masks_dir=config.masks_dir,
        predictions_dir=config.predictions_dir,
        output_viz_dir=config.visualizations_dir,
        year=year,
        max_tiles=50,  # N√∫mero m√°ximo de visualizaciones
        selection_mode='best'  # 'best', 'worst', 'random', 'all'
    )

    # ====================================
    # PASO 4.6: VISUALIZACI√ìN COMPARATIVA 3√ó5
    print("\n" + "="*80)
    print(f"PASO 4.6: VISUALIZACI√ìN COMPARATIVA 3√ó5 - A√ëO {year}")
    print("="*80)

    try:
        comparative_viz_path = generate_comparative_visualization_3x5(
            checkpoint_path=config.checkpoint_path,
            images_dir=config.images_dir,
            masks_dir=config.masks_dir,
            output_dir=config.mosaic_dir,
            device=device,
            threshold=threshold,
            year=year
        )
    except Exception as e:
        print(f"‚ö†Ô∏è  Error al generar visualizaci√≥n comparativa: {e}")
        import traceback
        traceback.print_exc()

    # PASO 5: ESTAD√çSTICAS DE √ÅREA
    # ====================================
    
    print("\n" + "="*80)
    print(f"PASO 5: C√ÅLCULO DE ESTAD√çSTICAS DE √ÅREA - A√ëO {year}")
    print("="*80)
    
    report_path = config.mosaic_dir / f'reporte_area_{year}.txt'
    
    calculate_area_statistics(
        mosaic_path=str(mosaic_path),
        output_report_path=str(report_path),
        year=year
    )

    # ====================================
    # PASO 6: GENERACI√ìN DE MOSAICOS DE FALSO COLOR
    # ====================================

    print("\n" + "="*80)
    print(f"PASO 6: GENERACI√ìN DE MOSAICOS DE FALSO COLOR - A√ëO {year}")
    print("="*80)

    # Ruta al shapefile del √°rea de estudio (Jambeli)
    shapefile_path = Path('/Users/elvissanchez/Documents/GitHub/thesis_project/data/archive_Shape/Jambeli_corregido/Area_Estudio_Jambeli.shp')

    false_color_paths = []
    if shapefile_path.exists():
        try:
            # Instanciar generador de falso color
            false_color_generator = FalseColorMosaicGenerator(
                year=year,
                images_dir=config.images_dir,
                output_dir=config.mosaic_dir,
                shapefile_path=shapefile_path
            )

            # Generar mosaicos de falso color (infrarrojo y agricultura)
            false_color_paths = false_color_generator.generate_all_false_color_images()

            print(f"\n‚úÖ Mosaicos de falso color generados exitosamente")

        except Exception as e:
            print(f"\n‚ö†Ô∏è  Error al generar mosaicos de falso color: {e}")
            import traceback
            traceback.print_exc()
    else:
        print(f"‚ö†Ô∏è  Shapefile no encontrado: {shapefile_path}")
        print("   Saltando generaci√≥n de mosaicos de falso color...")

    # ====================================
    # RESUMEN FINAL
    # ====================================
    
    print("\n" + "="*80)
    print(f"‚úÖ PROCESO COMPLETADO EXITOSAMENTE - A√ëO {year}")
    print("="*80)
    print(f"\nüìÅ ARCHIVOS GENERADOS:")
    print(f"   Directorio ra√≠z:        {config.output_base_dir}")
    print(f"   Teselas predichas:      {config.predictions_dir}/ ({len(pred_files)} archivos)")
    
    if cm is not None:
        print(f"\n   üìä M√âTRICAS DE EVALUACI√ìN:")
        print(f"   Matriz de confusi√≥n:    {config.metrics_dir / 'confusion_matrix.png'}")
        print(f"   Gr√°fico de m√©tricas:    {config.metrics_dir / 'metricas_rendimiento.png'}")
        print(f"   An√°lisis avanzado:      {config.metrics_dir / f'analisis_metricas_{year}.png'}")
        print(f"   Curva ROC:              {config.metrics_dir / f'curva_roc_{year}.png'}")
        print(f"   Casos destacados:       {config.metrics_dir / f'casos_destacados_{year}.png'}")
        print(f"   Reporte detallado:      {config.metrics_dir / 'reporte_metricas.txt'}")
        print(f"   M√©tricas JSON:          {config.metrics_dir / 'metricas.json'}")
    
    print(f"\n   üó∫Ô∏è MOSAICO Y VISUALIZACI√ìN:")
    print(f"   Mosaico GeoTIFF:        {mosaic_path}")
    print(f"   Visualizaci√≥n:          {viz_path}")
    print(f"   Reporte de √°rea:        {report_path}")

    print(f"\n   üé® VISUALIZACIONES INDIVIDUALES:")
    print(f"   Directorio:             {config.visualizations_dir}/")
    print(f"   Teselas visualizadas:   {viz_count} comparaciones RGB|GT|Pred")

    if len(false_color_paths) > 0:
        print(f"\n   üåà MOSAICOS DE FALSO COLOR:")
        for fc_path in false_color_paths:
            print(f"   {fc_path.name:30s} ‚Üí {fc_path}")

    if cm is not None:
        print(f"\nüéØ RENDIMIENTO DEL MODELO (A√ëO {year}):")
        print(f"   Accuracy:    {metrics['accuracy']*100:.2f}%")
        print(f"   F1-Score:    {metrics['f1_score']:.4f}")
        print(f"   Mean IoU:    {metrics['mean_iou']:.4f}")

    if advanced_metrics is not None:
        print(f"\nüìà M√âTRICAS AVANZADAS (ROC):")
        print(f"   ROC AUC:               {advanced_metrics['roc_auc']:.4f}")
        print(f"   Average Precision:     {advanced_metrics['avg_precision']:.4f}")
        print(f"   Threshold √≥ptimo (ROC): {advanced_metrics['optimal_threshold_roc']:.3f}")
        print(f"   Threshold √≥ptimo (F1):  {advanced_metrics['optimal_threshold_f1']:.3f}")

    print("\nüå≥ El mosaico est√° listo para an√°lisis en SIG (QGIS, ArcGIS, etc.)")
    print("="*80)


#====================================
# ‚≠ê PUNTO DE ENTRADA PRINCIPAL
#====================================

if __name__ == '__main__':
    
    # ============================================
    # üîß CONFIGURACI√ìN - MODIFICAR AQU√ç
    # ============================================
    
    # ‚≠ê PAR√ÅMETRO PRINCIPAL: A√ëO DE AN√ÅLISIS
    YEAR = 2025  # ‚Üê Cambiar este valor para analizar otro a√±o
    
    # Directorios
    BASE_DIR = '/Users/elvissanchez/Documents/GitHub/thesis_project/data/processed/test'
    CHECKPOINT_PATH = '/Users/elvissanchez/Documents/GitHub/thesis_project/checkpoints/MultiBranch-UNetPP-resnet101-fpn-Sentinel2-epoch=45-val_iou=0.8174.ckpt'
    # /Users/elvissanchez/Documents/GitHub/thesis_project/checkpoints/UnetPlusPlus-resnet34-15-Dic-25-epoch=95-val_iou=0.8954.ckpt
    OUTPUT_BASE_DIR = 'predicciones_por_a√±o'
    
    # ‚≠ê UMBRAL DE DECISI√ìN
    # 
    # ‚úÖ OPTIMIZADO tras an√°lisis de normalizaci√≥n:
    # - Las im√°genes de GEE ya vienen normalizadas [0, 1]
    # - Se elimin√≥ normalizaci√≥n percentil redundante que comprim√≠a rango
    # - Threshold 0.20 optimizado para valores espectrales reales
    # 
    # Basado en an√°lisis de distribuci√≥n de probabilidades:
    # - Threshold 0.50: Recall ~43% (con normalizaci√≥n redundante)
    # - Threshold 0.20: Recall ~52-55% (sin normalizaci√≥n redundante) ‚Üê RECOMENDADO
    # 
    # Ganancia estimada: +8-10 pp en recall con -2 pp en precision
    PREDICTION_THRESHOLD = 0.50
    
    # ‚≠ê‚≠ê‚≠ê NUEVO: POST-PROCESAMIENTO MORFOL√ìGICO ‚≠ê‚≠ê‚≠ê
    # 
    # T√©cnica validada cient√≠ficamente para refinar segmentaciones:
    # - Pham & Yoshino (2016) Remote Sensing of Environment
    # - Chen et al. (2020) ISPRS Journal
    # - Wang et al. (2023) Remote Sensing of Environment
    # 
    # Justificaci√≥n ecol√≥gica:
    # Los manglares crecen en parches continuos debido a crecimiento 
    # lateral de ra√≠ces (Tomlinson, 2016). Las discontinuidades en 
    # predicciones reflejan variabilidad espectral interna m√°s que 
    # fragmentaci√≥n real.
    #
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # CONFIGURACI√ìN:
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    #
    # USE_POSTPROCESSING: True/False
    #   True  = Aplica operaciones morfol√≥gicas (RECOMENDADO)
    #   False = Solo usa threshold (para comparaci√≥n baseline)
    #
    # POSTPROC_MODE: 'conservative' / 'moderate' / 'none'
    #   'conservative' = Kernel 3x3, cambio m√≠nimo
    #                    Ganancia: +2-3 pp recall
    #                    Recomendado para tesis (cient√≠ficamente conservador)
    #   
    #   'moderate'     = Kernel 5x5, m√°s correcci√≥n
    #                    Ganancia: +3-4 pp recall
    #                    Validado en Pham & Yoshino (2016)
    #   
    #   'none'         = Sin post-procesamiento
    #                    (equivalente a USE_POSTPROCESSING=False)
    #
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # RESULTADOS ESPERADOS (con threshold 0.20):
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    #
    # Sin post-proc:              Con post-proc (conservative):
    # Recall:    ~46.5%           Recall:    ~49.2% (+2.7 pp)
    # Precision: ~89.5%           Precision: ~89.1% (-0.4 pp)
    # F1-Score:  ~0.611           F1-Score:  ~0.635 (+0.024)
    # IoU:       ~0.630           IoU:       ~0.648 (+0.018)
    #
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    USE_POSTPROCESSING = True              # ‚Üê ACTIVAR/DESACTIVAR
    POSTPROC_MODE = 'conservative'         # ‚Üê 'conservative', 'moderate', 'none'
    
    # ============================================
    # üöÄ EJECUTAR PIPELINE
    # ============================================
    
    run_pipeline(
        year=YEAR,
        base_dir=BASE_DIR,
        checkpoint_path=CHECKPOINT_PATH,
        output_base_dir=OUTPUT_BASE_DIR,
        threshold=PREDICTION_THRESHOLD,
        use_postproc=USE_POSTPROCESSING,
        postproc_mode=POSTPROC_MODE
    )

    # ============================================
    # üó∫Ô∏è AN√ÅLISIS ESPACIAL DE ERRORES
    # ============================================

    print(f"\n\n{'='*80}")
    print("INICIANDO AN√ÅLISIS ESPACIAL DE ERRORES")
    print(f"{'='*80}\n")

    try:
        from spatial_error_analysis import SpatialErrorAnalyzer

        analyzer = SpatialErrorAnalyzer(
            year=YEAR,
            base_dir=Path.cwd(),  # Directorio actual
            pixel_size=10.0
        )

        analyzer.run_full_analysis()

    except Exception as e:
        print(f"‚ö†Ô∏è  Error en an√°lisis espacial: {e}")
        print("El pipeline principal se complet√≥ correctamente.")
        import traceback
        traceback.print_exc()

    # ============================================
    # üìù PARA AN√ÅLISIS MULTITEMPORAL
    # ============================================
    
    # Ejemplo: procesar m√∫ltiples a√±os secuencialmente
    # 
    # for year in [2020, 2021, 2022, 2023]:
    #     print(f"\n\n{'='*80}")
    #     print(f"PROCESANDO A√ëO {year}")
    #     print(f"{'='*80}\n")
    #     
    #     run_pipeline(
    #         year=year,
    #         base_dir=BASE_DIR,
    #         checkpoint_path=CHECKPOINT_PATH,
    #         output_base_dir=OUTPUT_BASE_DIR,
    #         threshold=PREDICTION_THRESHOLD,
    #         use_postproc=USE_POSTPROCESSING,
    #         postproc_mode=POSTPROC_MODE
    #     )
    
    # ============================================
    # üî¨ PARA COMPARACI√ìN ABLATION STUDY
    # ============================================
    
    # Para tu tesis, ejecuta m√∫ltiples configuraciones y compara:
    #
    # configs = [
    #     {'threshold': 0.50, 'postproc': False, 'mode': 'none'},      # Baseline
    #     {'threshold': 0.20, 'postproc': False, 'mode': 'none'},      # Solo threshold
    #     {'threshold': 0.20, 'postproc': True, 'mode': 'conservative'}, # Threshold + Post-proc
    # ]
    #
    # for i, cfg in enumerate(configs):
    #     print(f"\n{'='*80}")
    #     print(f"CONFIGURACI√ìN {i+1}/{len(configs)}")
    #     print(f"{'='*80}")
    #     run_pipeline(YEAR, BASE_DIR, CHECKPOINT_PATH, 
    #                  f"{OUTPUT_BASE_DIR}_config{i+1}",
    #                  cfg['threshold'], cfg['postproc'], cfg['mode'])
